# Consul Service Registration, Node Registry, and Introspection Research

**Research Date:** October 30, 2025
**Correlation ID:** e3e1196c-ff94-47d8-b91b-88cb58b81216
**Research Method:** Comprehensive Codebase Analysis
**Status:** ‚úÖ Complete

---

## Executive Summary

This document provides comprehensive research on the OmniNode Bridge's **two-way registration system** that enables:

1. **Consul Service Discovery** - Dynamic service registration with health checks
2. **NodeBridgeRegistry** - Central registry service consuming introspection events
3. **Node Introspection** - Self-discovery and capability broadcasting via IntrospectionMixin
4. **Two-Way Registration** - Bidirectional node discovery (nodes‚ÜíConsul, Consul‚Üínodes)

**Key Findings:**

- ‚úÖ **Architecture Complete**: Full two-way registration design documented and implemented
- ‚ö†Ô∏è **Implementation Status**: Core code complete but **backend integrations pending** (Consul, PostgreSQL, Kafka methods stubbed)
- ‚ùå **Current State**: System operates in **cache-only mode** - no actual service registration occurring
- üìã **Documentation**: Extensive documentation exists with clear implementation roadmap

**Current Gaps:**

1. NodeBridgeRegistry container **not deployed** (no registry service running)
2. PostgreSQL `node_registrations` table **not created** (migration 005 not applied)
3. Backend integrations **stubbed** (Consul, PostgreSQL, Kafka methods need implementation)
4. Service registration **not operational** (no services in Consul, no records in PostgreSQL)

---

## 1. Consul Service Registration

### 1.1 Architecture

Consul provides **dynamic service discovery** with automatic health monitoring and DNS-based lookup. Services register themselves on startup and are automatically removed if health checks fail.

**Registration Flow:**

```
Node Startup ‚Üí Extract Metadata ‚Üí Register with Consul ‚Üí Health Checks ‚Üí Service Available
     ‚Üì
  Publish NODE_INTROSPECTION event to Kafka
     ‚Üì
  NodeBridgeRegistry consumes event
     ‚Üì
  Dual Registration: Consul + PostgreSQL
```

### 1.2 Registration Process

**Code Location:** `/src/omninode_bridge/services/metadata_stamping/registry/consul_client.py`

**Class:** `RegistryConsulClient`

**Registration Method:**

```python
async def register_service(self, settings: Any = None) -> bool:
    """
    Register service with Consul.

    Creates service entry with:
    - Service name, ID, address, port
    - Health check configuration
    - Service tags for discovery
    - Metadata (via tags in MVP)
    """
    service_name = "metadata-stamping-service"
    service_id = f"{service_name}-{service_host}-{service_port}"

    # Register with Consul
    self.consul.agent.service.register(
        name=service_name,
        service_id=service_id,
        address=service_host,
        port=service_port,
        tags=["omninode", "o.n.e.v0.1"],
        http=health_check_url,
        interval="15s",
        timeout="10s"
    )
```

**File References:**

- Implementation: `src/omninode_bridge/services/metadata_stamping/registry/consul_client.py:60-139`
- Service Registration: Lines 110-124
- Health Check Configuration: Lines 97-99

### 1.3 Service Manifest Structure

**Location:** `/src/omninode_bridge/nodes/distributed_lock_effect/v1_0_0/service_manifest.yaml`

**Example Manifest:**

```yaml
service:
  name: distributed-lock-effect
  id: distributed-lock-effect-v1-{{ instance_id }}
  port: 8062

  tags:
    - onex-node
    - effect
    - distributed-lock
    - v1.0.0

  meta:
    version: "1.0.0"
    node_type: effect
    capabilities: lock_acquire,lock_release,lock_extend
    performance_target_ms: "50"

  # Health Check Configuration
  health_check:
    http: "http://{{ service_host }}:8062/health"
    interval: "30s"
    timeout: "10s"
    deregister_critical_service_after: "90s"

  # Service Mesh Configuration
  connect:
    sidecar_service:
      port: 8063
      proxy:
        upstreams:
          - destination_name: postgres
            local_bind_port: 5432
```

**File Reference:** `src/omninode_bridge/nodes/distributed_lock_effect/v1_0_0/service_manifest.yaml:1-69`

### 1.4 Health Check Configuration

Consul actively monitors registered services via HTTP health checks:

**Configuration Parameters:**

| Parameter | Value | Purpose |
|-----------|-------|---------|
| `interval` | `30s` | Check frequency |
| `timeout` | `10s` | Response timeout |
| `deregister_critical_service_after` | `90s` | Auto-remove unhealthy services |
| `success_before_passing` | `2` | Consecutive successes required |
| `failures_before_critical` | `3` | Consecutive failures before critical |

**Health Check Endpoints:**

- **Primary:** `/health` - Overall service health
- **Readiness:** `/health/ready` - Service ready to accept requests
- **Component-Specific:** `/health/postgres`, `/health/locks` - Individual component health

**File Reference:** `src/omninode_bridge/nodes/distributed_lock_effect/v1_0_0/service_manifest.yaml:22-29`

### 1.5 Configuration Requirements

**Environment Variables:**

```bash
# Consul Configuration
CONSUL_HOST=192.168.86.200
CONSUL_PORT=28500
CONSUL_HTTP_TOKEN=  # Optional ACL token

# Service Configuration
SERVICE_PORT=8053
SERVICE_HOST=localhost
LOCAL_IP=192.168.86.200  # For remote Consul health checks
```

**Infrastructure:**

- **Consul Container:** `omninode-bridge-consul` (running, healthy)
- **Consul API:** http://192.168.86.200:28500
- **Consul DNS:** 192.168.86.200:28600
- **Consul UI:** http://192.168.86.200:28500/ui

**Current Status:**

```bash
$ curl -s http://192.168.86.200:28500/v1/agent/services | python3 -m json.tool
{}  # No services registered
```

---

## 2. NodeBridgeRegistry (Central Registration Service)

### 2.1 Purpose and Responsibilities

**NodeBridgeRegistry** is the central service that:

1. **Consumes** introspection events from Kafka
2. **Performs** dual registration in Consul + PostgreSQL
3. **Requests** nodes to re-broadcast introspection on startup
4. **Monitors** health of registration services
5. **Manages** node lifecycle and cleanup

**Code Location:** `/src/omninode_bridge/nodes/registry/v1_0_0/node.py`

**Class:** `NodeBridgeRegistry(NodeEffect, HealthCheckMixin, IntrospectionMixin)`

**File Reference:** `src/omninode_bridge/nodes/registry/v1_0_0/node.py:122-180`

### 2.2 Architecture

**NodeBridgeRegistry Design:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   NodeBridgeRegistry                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
‚îÇ  ‚îÇ Kafka Consumer ‚îÇ         ‚îÇ Self-Discovery ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ (Introspection ‚îÇ         ‚îÇ (Introspection ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ     Events)    ‚îÇ         ‚îÇ     Mixin)     ‚îÇ              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
‚îÇ          ‚îÇ                          ‚îÇ                         ‚îÇ
‚îÇ          ‚îÇ                          ‚îÇ                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
‚îÇ  ‚îÇ    Dual Registration Orchestration        ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ    (Atomic Transaction Pattern)           ‚îÇ              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
‚îÇ          ‚îÇ                      ‚îÇ                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
‚îÇ  ‚îÇ Consul Client    ‚îÇ   ‚îÇ PostgreSQL Client ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ (Service         ‚îÇ   ‚îÇ (Tool Registry)   ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ  Discovery)      ‚îÇ   ‚îÇ                   ‚îÇ              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
‚îÇ                                                                ‚îÇ
‚îÇ  Background Tasks:                                            ‚îÇ
‚îÇ  - Kafka Consumer (continuous)                                ‚îÇ
‚îÇ  - Cleanup Task (hourly)                                      ‚îÇ
‚îÇ  - Memory Monitor (5 min)                                     ‚îÇ
‚îÇ  - Heartbeat Broadcast (30s)                                  ‚îÇ
‚îÇ                                                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2.3 Production-Ready Features

**Implemented Features:**

1. **Memory Leak Prevention**: TTL cache for offset tracking (max 10,000 offsets, 1-hour TTL)
2. **Race Condition Prevention**: Cleanup locks for safe background task management
3. **Circuit Breaker Pattern**: Robust error recovery with exponential backoff
4. **Atomic Registration**: Saga pattern preventing partial state
5. **Security-Aware Logging**: Sensitive data masking (passwords, tokens, secrets)
6. **Configurable Values**: Environment-based configuration
7. **Performance Monitoring**: Real-time memory and performance metrics
8. **Self-Registration**: Registry registers itself using IntrospectionMixin (MVP)

**Code References:**

- Circuit Breaker: `src/omninode_bridge/nodes/registry/v1_0_0/node.py:119-125` (configuration)
- Atomic Registration: Documented in `docs/architecture/DUAL_REGISTRATION_ARCHITECTURE.md:127-156`
- Security Logging: `src/omninode_bridge/nodes/registry/v1_0_0/node.py:137-145`

### 2.4 Registration Methods

**Current Implementation Status:**

‚ö†Ô∏è **Backend integrations are STUBBED** - architecture complete but methods not implemented:

```python
async def _register_with_consul(self, introspection: ModelNodeIntrospectionEvent):
    """Register node with Consul. [STUBBED - needs implementation]"""
    pass

async def _register_with_postgres(self, introspection: ModelNodeIntrospectionEvent):
    """Register node with PostgreSQL. [STUBBED - needs implementation]"""
    pass

async def _publish_to_kafka(self, event: ModelOnexEnvelopeV1):
    """Publish event to Kafka. [STUBBED - needs implementation]"""
    pass
```

**Expected Flow (Post-Implementation):**

```python
async def dual_register(self, introspection: ModelNodeIntrospectionEvent):
    """
    Perform atomic dual registration using Saga pattern.

    Steps:
    1. Register with Consul
    2. Register with PostgreSQL
    3. If either fails, rollback successful registrations
    4. Update in-memory cache
    5. Publish confirmation event (optional)
    """
```

### 2.5 API Endpoints

**Health Check:**

```bash
GET http://localhost:8080/health
```

**Response:**

```json
{
  "status": "healthy",
  "registry_id": "registry-abc123",
  "environment": "development",
  "checks": {
    "background_tasks": {
      "consumer_task_running": true,
      "cleanup_task_running": true
    },
    "services": {
      "kafka_client_available": true,
      "consul_client_available": true,
      "postgres_client_available": true
    },
    "circuit_breakers": {
      "registration_circuit": "closed"
    }
  },
  "metrics": {
    "registration": {
      "total_registrations": 1523,
      "successful_registrations": 1498
    }
  }
}
```

### 2.6 Current Implementation Status

**Status:** ‚ö†Ô∏è **Architecture Complete, Backend Integrations Pending**

- ‚úÖ Core orchestration logic implemented
- ‚úÖ Event consumption framework ready
- ‚úÖ Cache-only mode operational
- ‚è≥ Consul registration method stubbed (needs implementation)
- ‚è≥ PostgreSQL registration method stubbed (needs implementation)
- ‚è≥ Kafka event publishing method stubbed (needs implementation)
- ‚ùå Container not deployed (service not running)

**Documentation References:**

- Full Architecture: `docs/architecture/DUAL_REGISTRATION_ARCHITECTURE.md`
- Implementation Status: `docs/architecture/SERVICE_REGISTRATION_STATUS.md`
- Planning: `docs/planning/MVP_REGISTRY_SELF_REGISTRATION.md`

---

## 3. Node Introspection Mechanism

### 3.1 Overview

**IntrospectionMixin** provides nodes with self-discovery capabilities, enabling them to:

1. **Extract** their own capabilities, endpoints, and state
2. **Broadcast** introspection events to Kafka
3. **Respond** to registry requests for re-broadcast
4. **Maintain** periodic heartbeat

**Code Location:** `/src/omninode_bridge/nodes/mixins/introspection_mixin.py`

**Class:** `IntrospectionMixin`

**File Reference:** `src/omninode_bridge/nodes/mixins/introspection_mixin.py:143-165`

### 3.2 Integration Pattern

**3-Step Integration:**

```python
from omninode_bridge.nodes.mixins import NodeIntrospectionMixin

class NodeBridgeOrchestrator(NodeOrchestrator, HealthCheckMixin, NodeIntrospectionMixin):
    def __init__(self, container: ModelONEXContainer):
        super().__init__(container)
        self.initialize_introspection()  # Step 1: Initialize

    async def startup(self):
        await self.publish_introspection(reason="startup")  # Step 2: Broadcast
        await self.start_introspection_tasks()  # Step 3: Start background tasks

    async def shutdown(self):
        await self.stop_introspection_tasks()
```

**File Reference:** `docs/architecture/two-way-registration/NODE_INTROSPECTION_INTEGRATION.md:20-56`

### 3.3 Metadata Exposed

**Introspection Data Structure:**

```python
{
    "node_id": "orchestrator-v1_0_0-abc123",
    "node_name": "NodeBridgeOrchestrator",
    "node_type": "orchestrator",
    "node_version": "1.0.0",

    "capabilities": {
        "node_type": "orchestrator",
        "node_version": "1.0.0",

        "fsm_states": {
            "supported_states": ["PENDING", "PROCESSING", "COMPLETED", "FAILED"],
            "active_workflows": 5,
            "active_states": ["PROCESSING", "COMPLETED"]
        },

        "supported_operations": [
            "execute_orchestration",
            "coordinate_workflow",
            "manage_state",
            "route_operations"
        ],

        "performance": {
            "operations_tracked": 3,
            "metrics_available": true
        },

        "resource_limits": {
            "cpu_cores_available": 8,
            "memory_available_gb": 12.5,
            "current_memory_usage_mb": 245.6
        },

        "service_integration": {
            "metadata_stamping": "http://metadata-stamping:8053",
            "onextree": "http://onextree:8080"
        }
    },

    "endpoints": {
        "health": "http://localhost:8080/health",
        "api": "http://localhost:8080",
        "orchestration": "http://localhost:8080"
    },

    "configuration": {
        "node_ttl_hours": 24,
        "cleanup_interval_hours": 1
    },

    "current_state": {
        "status": "active",
        "uptime_seconds": 3600,
        "workflow_states": {
            "active_workflows": 5,
            "active_states": ["PROCESSING"]
        },
        "health_status": "healthy"
    },

    "introspection_timestamp": "2025-10-30T12:00:00Z",
    "introspection_version": "2.0.0-optimized"
}
```

**File Reference:** `docs/architecture/DUAL_REGISTRATION_ARCHITECTURE.md:250-298`

### 3.4 Broadcasting Triggers

**When Nodes Broadcast Introspection:**

1. **Startup**: Node initialization ‚Üí broadcast immediately
2. **Periodic Heartbeat**: Every 30 seconds (configurable)
3. **Registry Request**: When NodeBridgeRegistry requests re-broadcast
4. **Manual Trigger**: Via `publish_introspection(reason="manual")`
5. **State Changes**: After major capability or configuration updates

**Code Example:**

```python
# Startup introspection
await self.publish_introspection(reason="startup")

# After capability changes
await self.publish_introspection(reason="capability_change", force_refresh=True)

# In response to registry request
await self.publish_introspection(
    reason="registry_request",
    correlation_id=registry_correlation_id
)
```

**File Reference:** `docs/architecture/two-way-registration/NODE_INTROSPECTION_INTEGRATION.md:58-78`

### 3.5 Query Methods

**IntrospectionMixin API:**

| Method | Purpose | Returns |
|--------|---------|---------|
| `initialize_introspection()` | Initialize system | None |
| `publish_introspection(reason)` | Broadcast capabilities | bool |
| `get_introspection_data()` | Get full introspection | dict |
| `extract_capabilities()` | Extract node capabilities | dict |
| `get_endpoints()` | Get node endpoints | dict |
| `start_introspection_tasks()` | Start heartbeat/listener | None |
| `stop_introspection_tasks()` | Stop background tasks | None |

**File Reference:** `docs/architecture/two-way-registration/INTROSPECTION_QUICK_REFERENCE.md:25-34`

### 3.6 Performance Optimizations

**Performance Features:**

1. **Cached Imports**: Enum imports cached at module level
2. **Lazy Loading**: Heavy operations only when needed
3. **Memoization**: Expensive operations cached (5-minute TTL)
4. **Optimized Reflection**: Reduced attribute access overhead
5. **Efficient State Discovery**: FSM state discovery with caching

**Cache Configuration:**

```python
# Constants (module-level)
CACHE_TTL_SECONDS = 60  # General cache TTL
CURRENT_STATE_CACHE_TTL_SECONDS = 30  # State cache TTL
DEFAULT_HEARTBEAT_INTERVAL_SECONDS = 30  # Heartbeat interval
```

**File References:**

- Performance Documentation: `src/omninode_bridge/nodes/mixins/introspection_mixin.py:1-12`
- Cache Constants: `src/omninode_bridge/nodes/mixins/introspection_mixin.py:24-28`
- Caching Logic: `src/omninode_bridge/nodes/mixins/introspection_mixin.py:58-141`

### 3.7 Example Implementation

**Orchestrator with Introspection:**

```python
class NodeBridgeOrchestrator(NodeOrchestrator, HealthCheckMixin, NodeIntrospectionMixin):
    def __init__(self, container: ModelONEXContainer):
        super().__init__(container)

        # Node configuration
        self.workflow_fsm_states = {}
        self.stamping_metrics = {}

        # Initialize systems
        self.initialize_health_checks()
        self.initialize_introspection()

    async def startup(self):
        # Broadcast startup introspection
        success = await self.publish_introspection(reason="startup")
        if not success:
            logger.warning("Failed to broadcast startup introspection")

        # Start background tasks
        await self.start_introspection_tasks(
            enable_heartbeat=True,
            heartbeat_interval_seconds=30,
            enable_registry_listener=True
        )

    async def shutdown(self):
        # Stop background tasks first
        await self.stop_introspection_tasks()

        # Optional: broadcast shutdown status
        await self.publish_introspection(reason="shutdown")
```

**File Reference:** `docs/architecture/two-way-registration/NODE_INTROSPECTION_INTEGRATION.md:425-459`

---

## 4. Two-Way Registration Flow

### 4.1 Complete Registration Process

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Two-Way Registration Flow                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

1. Service Starts
   ‚Üì
2. Initialize IntrospectionMixin
   ‚Üì
3. Gather introspection data (capabilities, endpoints, state)
   ‚Üì
4. Create ModelNodeIntrospectionEvent
   ‚Üì
5. Wrap in OnexEnvelopeV1
   ‚Üì
6. Publish to Kafka topic: {env}.omninode_bridge.onex.evt.node-introspection.v1
   ‚Üì
7. NodeBridgeRegistry consumes event
   ‚Üì
8. Validate introspection data
   ‚Üì
9. Atomic dual registration (Saga pattern):
   ‚îú‚îÄ 9a. Register in Consul (health checks, tags, metadata)
   ‚îÇ  ‚îî‚îÄ Success? ‚Üí Continue
   ‚îÇ  ‚îî‚îÄ Failure? ‚Üí Abort (no partial registration)
   ‚îÇ
   ‚îî‚îÄ 9b. Register in PostgreSQL (capabilities, endpoints, metadata)
      ‚îî‚îÄ Success? ‚Üí Complete
      ‚îî‚îÄ Failure? ‚Üí Rollback Consul registration
   ‚Üì
10. Update in-memory cache in NodeBridgeRegistry
   ‚Üì
11. Service now discoverable via:
    - Consul: curl http://consul:8500/v1/health/service/{service-name}
    - PostgreSQL: SELECT * FROM node_registrations WHERE node_id = '{node-id}'
```

**File Reference:** `docs/architecture/DUAL_REGISTRATION_ARCHITECTURE.md:341-373`

### 4.2 Node ‚Üí Consul Registration

**Step-by-Step:**

1. **Node publishes introspection event** to Kafka
2. **NodeBridgeRegistry consumes event** from Kafka
3. **Extracts metadata** from introspection payload
4. **Calls Consul API** to register service:

```python
# NodeBridgeRegistry calls Consul client
consul_result = await self.consul_client.register_service(
    service_name=f"{node_type}-{node_id}",
    service_id=f"{node_type}-{node_id}-{instance_id}",
    address=node_endpoints["api"],
    port=node_port,
    tags=["omninode", "bridge", "onex-v2.0"],
    health_check=node_endpoints["health"]
)
```

5. **Consul stores service** and begins health monitoring
6. **Service available** via Consul DNS and API

**Discovery Example:**

```bash
# DNS-based discovery
dig @consul -p 8600 orchestrator-service.service.consul

# API-based discovery
curl http://consul:8500/v1/health/service/orchestrator-service?passing=true
```

### 4.3 Consul ‚Üí Node Discovery

**Service Discovery Flow:**

1. **Client queries Consul** for service by name
2. **Consul returns** healthy service instances
3. **Client selects instance** (load balanced via DNS round-robin or client-side)
4. **Client connects** to service via returned address:port

**Use Cases:**

- **Dynamic Service Lookup**: "Find me a healthy orchestrator"
- **Load Balancing**: Consul DNS round-robin across instances
- **Health Monitoring**: Automatic removal of unhealthy services
- **Service Mesh**: Consul Connect for mTLS between services

**Example Query:**

```python
# Query Consul for healthy orchestrators
import consul

c = consul.Consul(host='consul', port=8500)
index, services = c.health.service('orchestrator-service', passing=True)

for service in services:
    address = service['Service']['Address']
    port = service['Service']['Port']
    print(f"Orchestrator available at {address}:{port}")
```

### 4.4 Bidirectional Health Checks

**Consul ‚Üí Node Health Monitoring:**

- Consul **actively polls** node health endpoints (every 30s)
- Node **responds** with health status
- Consul **marks unhealthy** if 3 consecutive failures
- Consul **auto-removes** after 90s of critical status

**Node ‚Üí Registry Heartbeat:**

- Node **publishes** NODE_HEARTBEAT events (every 30s)
- NodeBridgeRegistry **updates** last_heartbeat timestamp
- Registry **detects stale** nodes (no heartbeat > TTL)
- Registry **triggers cleanup** for stale nodes

**Health Check Flow:**

```
Consul Health Check (Pull):
  Consul ‚Üí HTTP GET /health ‚Üí Node ‚Üí 200 OK ‚Üí Service Passing

Node Heartbeat (Push):
  Node ‚Üí NODE_HEARTBEAT event ‚Üí Kafka ‚Üí NodeBridgeRegistry ‚Üí Update last_heartbeat
```

### 4.5 Dynamic Service Updates

**When node state changes:**

1. Node detects capability or configuration change
2. Node publishes updated NODE_INTROSPECTION event
3. NodeBridgeRegistry consumes updated event
4. Registry updates both Consul and PostgreSQL registrations
5. Updated metadata propagated to consumers

**Example:**

```python
# Orchestrator adds new capability
self.supported_operations.append("batch_processing")

# Broadcast updated introspection
await self.publish_introspection(
    reason="capability_change",
    force_refresh=True
)
```

---

## 5. Current Issues Identified

### 5.1 Missing Implementations

#### Issue 1: NodeBridgeRegistry Not Deployed

**Status:** ‚ùå **Critical**

**Evidence:**

```bash
$ docker ps | grep registry
(no results)
```

**Impact:**

- No consumer processing NODE_INTROSPECTION events
- Even if nodes broadcast, no one is listening
- Dual registration not occurring

**Root Cause:** Container not configured in docker-compose.yml

#### Issue 2: PostgreSQL Migration Not Applied

**Status:** ‚ùå **Critical**

**Evidence:**

```bash
$ docker exec omninode-bridge-postgres psql -U postgres -d omninode_bridge -c "\d node_registrations"
Did not find any relation named "node_registrations".
```

**Impact:**

- NodeBridgeRegistry cannot write to PostgreSQL
- Dual registration fails on PostgreSQL side

**Root Cause:** Migration 005 not applied

**File Reference:** `migrations/005_create_node_registrations.sql` (migration file exists)

#### Issue 3: Backend Integration Methods Stubbed

**Status:** ‚ö†Ô∏è **High Priority**

**Evidence:**

Code analysis shows registration methods are stubbed:

```python
# In NodeBridgeRegistry
async def _register_with_consul(self, introspection):
    """[STUBBED] - needs implementation"""
    pass

async def _register_with_postgres(self, introspection):
    """[STUBBED] - needs implementation"""
    pass
```

**Impact:**

- Registration logic exists but doesn't execute
- System operates in cache-only mode

**Root Cause:** Backend integrations deferred to Phase 3

**Documentation Reference:** `docs/architecture/SERVICE_REGISTRATION_STATUS.md:8-18`

#### Issue 4: Kafka Topics May Not Exist

**Status:** ‚ö†Ô∏è **Medium Priority**

**Evidence:** Not verified during research

**Expected Topics:**

- `dev.omninode_bridge.onex.evt.node-introspection.v1`
- `dev.omninode_bridge.onex.evt.node-heartbeat.v1`
- `dev.omninode_bridge.onex.evt.registry-request-introspection.v1`

**Verification Command:**

```bash
docker exec omninode-bridge-redpanda rpk topic list | grep introspection
```

### 5.2 Configuration Gaps

#### Issue 5: Service Introspection Broadcast Status Unknown

**Status:** ‚ö†Ô∏è **Unknown**

**Evidence:** No verification performed

**Questions:**

- Are orchestrator/reducer broadcasting introspection?
- Are NODE_INTROSPECTION events reaching Kafka?
- Are events properly formatted (OnexEnvelopeV1)?

**Verification Needed:**

```bash
# Check orchestrator logs for introspection
docker logs omninode-bridge-orchestrator --tail 100 | grep introspection

# Consume from introspection topic
docker exec omninode-bridge-redpanda rpk topic consume \
  dev.omninode_bridge.onex.evt.node-introspection.v1 \
  --num 10 \
  --format json
```

#### Issue 6: Environment Variables Not Fully Documented

**Status:** ‚ö†Ô∏è **Low Priority**

**Required Environment Variables:**

```bash
# Consul Configuration
CONSUL_HOST=192.168.86.200
CONSUL_PORT=28500
CONSUL_HTTP_TOKEN=  # Optional

# PostgreSQL Configuration
POSTGRES_HOST=192.168.86.200
POSTGRES_PORT=5436
POSTGRES_DATABASE=omninode_bridge
POSTGRES_USER=postgres
POSTGRES_PASSWORD=<secure_password>  # Required

# Kafka Configuration
KAFKA_BROKER_URL=192.168.86.200:9092
KAFKA_ENVIRONMENT=dev

# Registry Configuration
NODE_TTL_HOURS=24
CLEANUP_INTERVAL_HOURS=1
MAX_TRACKED_OFFSETS=10000
```

**File Reference:** `docs/architecture/DUAL_REGISTRATION_ARCHITECTURE.md:664-693`

### 5.3 Documentation Gaps

#### Issue 7: Code Generation Orchestrator Service Resolution Failure

**Status:** ‚ùå **Critical** (Original Issue)

**Evidence:**

Code generation orchestrator fails due to service resolution issues:

```
Error: Unable to resolve service 'database-adapter'
```

**Root Cause Analysis:**

1. **No Consul Registration**: Services not registered in Consul
2. **No NodeBridgeRegistry**: Central registry not running
3. **No Service Discovery**: Code gen orchestrator cannot find services

**Resolution Path:**

1. Deploy NodeBridgeRegistry container
2. Apply PostgreSQL migration
3. Implement backend integration methods
4. Verify service registration
5. Test code gen orchestrator service resolution

---

## 6. Remediation Steps

### 6.1 Phase 1: Infrastructure Setup (30 minutes)

**Priority:** ‚úÖ **CRITICAL** - Foundation for all other work

#### Step 1.1: Apply PostgreSQL Migration

**Commands:**

```bash
# Verify current migrations
docker exec omninode-bridge-postgres psql -U postgres -d omninode_bridge -c "\dt"

# Apply migration 005
docker exec omninode-bridge-postgres psql -U postgres -d omninode_bridge \
  -f /docker-entrypoint-initdb.d/005_create_node_registrations.sql

# Verify table created
docker exec omninode-bridge-postgres psql -U postgres -d omninode_bridge \
  -c "\d node_registrations"

# Verify indexes created
docker exec omninode-bridge-postgres psql -U postgres -d omninode_bridge \
  -c "\di node_registrations*"
```

**Expected Result:**

```sql
Table "public.node_registrations"
 Column        | Type                      | Nullable | Default
---------------+---------------------------+----------+---------
 node_id       | character varying(255)    | not null |
 node_type     | character varying(100)    | not null |
 capabilities  | jsonb                     |          | '{}'::jsonb
 endpoints     | jsonb                     |          | '{}'::jsonb
 health_status | character varying(50)     | not null | 'UNKNOWN'
 ...

Indexes:
    "node_registrations_pkey" PRIMARY KEY
    "idx_node_registrations_health" btree (health_status)
    "idx_node_registrations_type" btree (node_type)
```

**File Reference:** `migrations/005_create_node_registrations.sql`

#### Step 1.2: Verify Kafka Topics Exist

**Commands:**

```bash
# List all topics
docker exec omninode-bridge-redpanda rpk topic list

# Check for introspection topics
docker exec omninode-bridge-redpanda rpk topic list | grep introspection

# Create topics if missing
docker exec omninode-bridge-redpanda rpk topic create \
  dev.omninode_bridge.onex.evt.node-introspection.v1 \
  --partitions 3 \
  --replicas 1

docker exec omninode-bridge-redpanda rpk topic create \
  dev.omninode_bridge.onex.evt.node-heartbeat.v1 \
  --partitions 3 \
  --replicas 1

docker exec omninode-bridge-redpanda rpk topic create \
  dev.omninode_bridge.onex.evt.registry-request-introspection.v1 \
  --partitions 1 \
  --replicas 1
```

#### Step 1.3: Configure Environment Variables

**Create `.env` file:**

```bash
# Location: /Volumes/PRO-G40/Code/omninode_bridge/.env

# Consul
CONSUL_HOST=192.168.86.200
CONSUL_PORT=28500

# PostgreSQL
POSTGRES_HOST=192.168.86.200
POSTGRES_PORT=5436
POSTGRES_DATABASE=omninode_bridge
POSTGRES_USER=postgres
POSTGRES_PASSWORD=<your_secure_password>

# Kafka
KAFKA_BROKER_URL=192.168.86.200:9092
KAFKA_ENVIRONMENT=dev

# Registry
NODE_TTL_HOURS=24
CLEANUP_INTERVAL_HOURS=1
```

### 6.2 Phase 2: Backend Integration Implementation (2-3 days)

**Priority:** üî¥ **HIGH** - Core functionality

#### Step 2.1: Implement Consul Registration Method

**File:** `src/omninode_bridge/nodes/registry/v1_0_0/node.py`

**Method to Implement:**

```python
async def _register_with_consul(
    self, introspection: ModelNodeIntrospectionEvent
) -> dict[str, Any]:
    """
    Register node with Consul service discovery.

    Implementation required:
    1. Extract service metadata from introspection
    2. Call consul_client.register_service()
    3. Configure health checks
    4. Handle errors with circuit breaker
    5. Return registration result
    """
    # TODO: Implement Consul registration
    pass
```

**Reference Implementation:** `src/omninode_bridge/services/metadata_stamping/registry/consul_client.py:60-139`

#### Step 2.2: Implement PostgreSQL Registration Method

**File:** `src/omninode_bridge/nodes/registry/v1_0_0/node.py`

**Method to Implement:**

```python
async def _register_with_postgres(
    self, introspection: ModelNodeIntrospectionEvent
) -> dict[str, Any]:
    """
    Register node in PostgreSQL tool registry.

    Implementation required:
    1. Create NodeRegistrationCreate model
    2. Call node_repository.create_or_update()
    3. Handle JSONB serialization
    4. Handle errors with circuit breaker
    5. Return registration result
    """
    # TODO: Implement PostgreSQL registration
    pass
```

**Database Schema:** `migrations/005_create_node_registrations.sql`

#### Step 2.3: Implement Kafka Event Publishing

**File:** `src/omninode_bridge/nodes/registry/v1_0_0/node.py`

**Method to Implement:**

```python
async def _publish_to_kafka(
    self, event: ModelOnexEnvelopeV1, topic: str
) -> bool:
    """
    Publish event to Kafka topic.

    Implementation required:
    1. Serialize ModelOnexEnvelopeV1 to JSON
    2. Call kafka_client.produce()
    3. Handle serialization errors
    4. Handle Kafka errors with circuit breaker
    5. Return success/failure
    """
    # TODO: Implement Kafka publishing
    pass
```

#### Step 2.4: Implement Atomic Dual Registration

**File:** `src/omninode_bridge/nodes/registry/v1_0_0/node.py`

**Method to Implement:**

```python
async def _atomic_dual_register(
    self, introspection: ModelNodeIntrospectionEvent
) -> tuple[dict, dict]:
    """
    Perform atomic dual registration using Saga pattern.

    Implementation:
    1. Register with Consul
    2. If success, register with PostgreSQL
    3. If PostgreSQL fails, rollback Consul registration
    4. Return (consul_result, postgres_result)
    """
    try:
        # Phase 1: Consul registration
        consul_result = await self._register_with_consul(introspection)
        if not consul_result['success']:
            raise OnexError("Consul registration failed")

        # Phase 2: PostgreSQL registration
        try:
            postgres_result = await self._register_with_postgres(introspection)
            if not postgres_result['success']:
                # Rollback Consul
                await self._rollback_consul_registration(introspection.node_id)
                raise OnexError("PostgreSQL registration failed")
        except Exception as e:
            # Rollback Consul on PostgreSQL failure
            await self._rollback_consul_registration(introspection.node_id)
            raise

        return (consul_result, postgres_result)

    except Exception as e:
        # Log and re-raise
        logger.error(f"Atomic dual registration failed: {e}")
        raise
```

**File Reference:** `docs/architecture/DUAL_REGISTRATION_ARCHITECTURE.md:127-156` (design documentation)

### 6.3 Phase 3: Deployment (1 hour)

**Priority:** üî¥ **HIGH** - Service availability

#### Step 3.1: Create Docker Container Configuration

**File:** `deployment/docker-compose.bridge.yml`

**Add Registry Service:**

```yaml
omninode-bridge-registry:
  build:
    context: .
    dockerfile: Dockerfile.registry
  container_name: omninode-bridge-registry
  environment:
    - POSTGRES_HOST=192.168.86.200
    - POSTGRES_PORT=5436
    - POSTGRES_DB=omninode_bridge
    - POSTGRES_USER=postgres
    - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    - CONSUL_HOST=192.168.86.200
    - CONSUL_PORT=28500
    - KAFKA_BROKER_URL=192.168.86.200:9092
    - KAFKA_ENVIRONMENT=dev
    - NODE_TTL_HOURS=24
    - CLEANUP_INTERVAL_HOURS=1
  depends_on:
    - omninode-bridge-postgres
    - omninode-bridge-consul
    - omninode-bridge-redpanda
  networks:
    - omninode-bridge
  ports:
    - "8080:8080"  # Health/API endpoint
  healthcheck:
    test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
    interval: 30s
    timeout: 5s
    retries: 3
```

#### Step 3.2: Create Dockerfile

**File:** `Dockerfile.registry`

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install dependencies
COPY pyproject.toml poetry.lock ./
RUN pip install poetry && poetry install --no-dev

# Copy application code
COPY src/ ./src/
COPY migrations/ ./migrations/

# Set Python path
ENV PYTHONPATH=/app/src

# Run registry service
CMD ["poetry", "run", "python", "-m", "omninode_bridge.nodes.registry.v1_0_0.main_standalone"]
```

#### Step 3.3: Deploy Registry Service

**Commands:**

```bash
# Build and start registry
cd /Volumes/PRO-G40/Code/omninode_bridge
docker compose -f deployment/docker-compose.bridge.yml up -d omninode-bridge-registry

# Verify container running
docker ps | grep registry

# Check logs
docker logs omninode-bridge-registry --tail 50

# Verify health
curl http://localhost:8080/health
```

### 6.4 Phase 4: Verification (30 minutes)

**Priority:** ‚úÖ **CRITICAL** - Validate implementation

#### Step 4.1: Verify Kafka Message Flow

**Commands:**

```bash
# 1. Check orchestrator logs for introspection broadcast
docker logs omninode-bridge-orchestrator --tail 100 | grep introspection

# 2. Consume from introspection topic
docker exec omninode-bridge-redpanda rpk topic consume \
  dev.omninode_bridge.onex.evt.node-introspection.v1 \
  --num 10 \
  --format json

# 3. Check registry logs for consumption
docker logs omninode-bridge-registry --tail 100 | grep "Consumed introspection"
```

**Expected Output:**

```json
{
  "envelope_version": "1.0",
  "event_type": "NODE_INTROSPECTION",
  "source_node": "orchestrator-001",
  "payload": {
    "node_id": "orchestrator-001",
    "node_type": "orchestrator",
    "capabilities": { ... }
  }
}
```

#### Step 4.2: Verify Consul Registration

**Commands:**

```bash
# Query Consul for registered services
curl -s http://192.168.86.200:28500/v1/agent/services | python3 -m json.tool

# Check for orchestrator service
curl -s http://192.168.86.200:28500/v1/health/service/orchestrator-service | python3 -m json.tool

# Verify health checks
curl -s http://192.168.86.200:28500/v1/agent/checks | python3 -m json.tool
```

**Expected Output:**

```json
{
  "orchestrator-orchestrator-001-abc123": {
    "ID": "orchestrator-orchestrator-001-abc123",
    "Service": "orchestrator-service",
    "Tags": ["omninode", "bridge", "onex-v2.0"],
    "Address": "192.168.86.200",
    "Port": 8060
  }
}
```

#### Step 4.3: Verify PostgreSQL Registration

**Commands:**

```bash
# Query PostgreSQL for registered nodes
docker exec omninode-bridge-postgres psql -U postgres -d omninode_bridge << 'EOF'
SELECT
    node_id,
    node_type,
    health_status,
    last_heartbeat,
    capabilities->>'node_version' as version
FROM node_registrations
ORDER BY registered_at DESC;
EOF

# Verify orchestrator registration
docker exec omninode-bridge-postgres psql -U postgres -d omninode_bridge << 'EOF'
SELECT * FROM node_registrations
WHERE node_id LIKE 'orchestrator%';
EOF
```

**Expected Output:**

```
 node_id          | node_type    | health_status | last_heartbeat | version
------------------+--------------+---------------+----------------+---------
 orchestrator-001 | orchestrator | HEALTHY       | 2025-10-30...  | 1.0.0
```

#### Step 4.4: Test Service Discovery

**Commands:**

```bash
# Test DNS-based discovery (if Consul DNS configured)
dig @192.168.86.200 -p 28600 orchestrator-service.service.consul

# Test API-based discovery
curl -s "http://192.168.86.200:28500/v1/health/service/orchestrator-service?passing=true" \
  | python3 -m json.tool

# Test code gen orchestrator service resolution
docker exec omninode-bridge-code-gen-orchestrator \
  python -c "import consul; c = consul.Consul(host='192.168.86.200', port=28500); print(c.health.service('database-adapter', passing=True))"
```

#### Step 4.5: End-to-End Registration Test

**Test Script:**

```python
#!/usr/bin/env python3
"""End-to-end registration test."""

import asyncio
import requests
from datetime import UTC, datetime
from uuid import uuid4

async def test_e2e_registration():
    print("=== End-to-End Registration Test ===\n")

    # 1. Verify registry is running
    print("1. Checking NodeBridgeRegistry health...")
    health = requests.get("http://localhost:8080/health")
    print(f"   Status: {health.json()['status']}\n")

    # 2. Trigger orchestrator introspection
    print("2. Triggering orchestrator introspection...")
    # (Orchestrator should auto-broadcast on startup)

    # 3. Wait for propagation
    print("3. Waiting for registration propagation (5 seconds)...")
    await asyncio.sleep(5)

    # 4. Check Consul
    print("4. Checking Consul registration...")
    consul_services = requests.get("http://192.168.86.200:28500/v1/agent/services")
    services = consul_services.json()
    orchestrator_services = [s for s in services if 'orchestrator' in s.lower()]
    print(f"   Orchestrator services found: {len(orchestrator_services)}")
    if orchestrator_services:
        print(f"   Example: {orchestrator_services[0]}\n")

    # 5. Check PostgreSQL
    print("5. Checking PostgreSQL registration...")
    import psycopg2
    conn = psycopg2.connect(
        host="192.168.86.200",
        port=5436,
        database="omninode_bridge",
        user="postgres",
        password="your_password"  # pragma: allowlist secret
    )
    cur = conn.cursor()
    cur.execute("SELECT COUNT(*) FROM node_registrations WHERE node_type = 'orchestrator'")
    count = cur.fetchone()[0]
    print(f"   Orchestrator registrations: {count}\n")
    conn.close()

    # 6. Test service discovery
    print("6. Testing service discovery...")
    consul_health = requests.get(
        "http://192.168.86.200:28500/v1/health/service/orchestrator-service?passing=true"
    )
    healthy_instances = consul_health.json()
    print(f"   Healthy orchestrator instances: {len(healthy_instances)}\n")

    print("=== Test Complete ===")

if __name__ == "__main__":
    asyncio.run(test_e2e_registration())
```

**Run Test:**

```bash
cd /Volumes/PRO-G40/Code/omninode_bridge
poetry run python tests/e2e_registration_test.py
```

---

## 7. Architectural Diagrams

### 7.1 Complete System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        OmniNode Bridge Ecosystem                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ  Orchestrator    ‚îÇ  ‚îÇ    Reducer       ‚îÇ  ‚îÇ   Database       ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ    Node          ‚îÇ  ‚îÇ     Node         ‚îÇ  ‚îÇ   Adapter        ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ (IntrospectionM) ‚îÇ  ‚îÇ (IntrospectionM) ‚îÇ  ‚îÇ    Node          ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ           ‚îÇ                     ‚îÇ                      ‚îÇ                 ‚îÇ
‚îÇ           ‚îÇ NODE_INTROSPECTION events                  ‚îÇ                 ‚îÇ
‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ
‚îÇ                                 ‚îÇ                                        ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îÇ
‚îÇ                    ‚îÇ   Kafka Event Bus       ‚îÇ                          ‚îÇ
‚îÇ                    ‚îÇ   (Redpanda)            ‚îÇ                          ‚îÇ
‚îÇ                    ‚îÇ                         ‚îÇ                          ‚îÇ
‚îÇ                    ‚îÇ Topics:                 ‚îÇ                          ‚îÇ
‚îÇ                    ‚îÇ - node-introspection.v1 ‚îÇ                          ‚îÇ
‚îÇ                    ‚îÇ - node-heartbeat.v1     ‚îÇ                          ‚îÇ
‚îÇ                    ‚îÇ - registry-request.v1   ‚îÇ                          ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ
‚îÇ                                 ‚îÇ                                        ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                          ‚îÇ
‚îÇ                    ‚îÇ  NodeBridgeRegistry     ‚îÇ                          ‚îÇ
‚îÇ                    ‚îÇ  (Central Service)      ‚îÇ                          ‚îÇ
‚îÇ                    ‚îÇ                         ‚îÇ                          ‚îÇ
‚îÇ                    ‚îÇ  - Kafka Consumer       ‚îÇ                          ‚îÇ
‚îÇ                    ‚îÇ  - Dual Registration    ‚îÇ                          ‚îÇ
‚îÇ                    ‚îÇ  - Health Monitoring    ‚îÇ                          ‚îÇ
‚îÇ                    ‚îÇ  - TTL Cleanup          ‚îÇ                          ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ
‚îÇ                           ‚îÇ        ‚îÇ                                     ‚îÇ
‚îÇ            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                     ‚îÇ
‚îÇ            ‚îÇ                                       ‚îÇ                     ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ   ‚îÇ  Consul          ‚îÇ                  ‚îÇ  PostgreSQL         ‚îÇ         ‚îÇ
‚îÇ   ‚îÇ  Service         ‚îÇ                  ‚îÇ  Tool Registry      ‚îÇ         ‚îÇ
‚îÇ   ‚îÇ  Discovery       ‚îÇ                  ‚îÇ                     ‚îÇ         ‚îÇ
‚îÇ   ‚îÇ                  ‚îÇ                  ‚îÇ  Table:             ‚îÇ         ‚îÇ
‚îÇ   ‚îÇ  - DNS Lookup    ‚îÇ                  ‚îÇ  node_registrations ‚îÇ         ‚îÇ
‚îÇ   ‚îÇ  - Health Checks ‚îÇ                  ‚îÇ                     ‚îÇ         ‚îÇ
‚îÇ   ‚îÇ  - API Query     ‚îÇ                  ‚îÇ  Columns:           ‚îÇ         ‚îÇ
‚îÇ   ‚îÇ  - Tags/Meta     ‚îÇ                  ‚îÇ  - capabilities     ‚îÇ         ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ  - endpoints        ‚îÇ         ‚îÇ
‚îÇ            ‚îÇ                             ‚îÇ  - health_status    ‚îÇ         ‚îÇ
‚îÇ            ‚îÇ                             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ            ‚îÇ                                        ‚îÇ                     ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ   ‚îÇ         Service Discovery Consumers           ‚îÇ            ‚îÇ         ‚îÇ
‚îÇ   ‚îÇ         (Code Gen, Orchestration, etc.)       ‚îÇ            ‚îÇ         ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ                                                                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 7.2 Registration Event Flow

```
TIME ‚Üí

Node Startup:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  Node              Kafka           Registry        Consul    PostgreSQL
   ‚îÇ                 ‚îÇ                 ‚îÇ              ‚îÇ            ‚îÇ
   ‚îÇ 1. Initialize   ‚îÇ                 ‚îÇ              ‚îÇ            ‚îÇ
   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ                 ‚îÇ              ‚îÇ            ‚îÇ
   ‚îÇ                 ‚îÇ                 ‚îÇ              ‚îÇ            ‚îÇ
   ‚îÇ 2. Publish      ‚îÇ                 ‚îÇ              ‚îÇ            ‚îÇ
   ‚îÇ  Introspection  ‚îÇ                 ‚îÇ              ‚îÇ            ‚îÇ
   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ                 ‚îÇ              ‚îÇ            ‚îÇ
   ‚îÇ                 ‚îÇ                 ‚îÇ              ‚îÇ            ‚îÇ
   ‚îÇ                 ‚îÇ 3. Consume      ‚îÇ              ‚îÇ            ‚îÇ
   ‚îÇ                 ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ              ‚îÇ            ‚îÇ
   ‚îÇ                 ‚îÇ                 ‚îÇ              ‚îÇ            ‚îÇ
   ‚îÇ                 ‚îÇ                 ‚îÇ 4. Register  ‚îÇ            ‚îÇ
   ‚îÇ                 ‚îÇ                 ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ            ‚îÇ
   ‚îÇ                 ‚îÇ                 ‚îÇ              ‚îÇ            ‚îÇ
   ‚îÇ                 ‚îÇ                 ‚îÇ              ‚îÇ 5. Store   ‚îÇ
   ‚îÇ                 ‚îÇ                 ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ
   ‚îÇ                 ‚îÇ                 ‚îÇ              ‚îÇ            ‚îÇ
   ‚îÇ                 ‚îÇ                 ‚îÇ              ‚îÇ 6. Success ‚îÇ
   ‚îÇ                 ‚îÇ                 ‚îÇ<‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
   ‚îÇ                 ‚îÇ                 ‚îÇ              ‚îÇ            ‚îÇ
   ‚îÇ                 ‚îÇ                 ‚îÇ 7. Health    ‚îÇ            ‚îÇ
   ‚îÇ<‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§            ‚îÇ
   ‚îÇ                 ‚îÇ                 ‚îÇ              ‚îÇ            ‚îÇ
   ‚îÇ 8. 200 OK       ‚îÇ                 ‚îÇ              ‚îÇ            ‚îÇ
   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ            ‚îÇ
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

Periodic Heartbeat (every 30s):
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  Node              Kafka           Registry        Consul    PostgreSQL
   ‚îÇ                 ‚îÇ                 ‚îÇ              ‚îÇ            ‚îÇ
   ‚îÇ 1. Heartbeat    ‚îÇ                 ‚îÇ              ‚îÇ            ‚îÇ
   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ                 ‚îÇ              ‚îÇ            ‚îÇ
   ‚îÇ                 ‚îÇ                 ‚îÇ              ‚îÇ            ‚îÇ
   ‚îÇ                 ‚îÇ 2. Consume      ‚îÇ              ‚îÇ            ‚îÇ
   ‚îÇ                 ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ              ‚îÇ            ‚îÇ
   ‚îÇ                 ‚îÇ                 ‚îÇ              ‚îÇ            ‚îÇ
   ‚îÇ                 ‚îÇ                 ‚îÇ              ‚îÇ 3. Update  ‚îÇ
   ‚îÇ                 ‚îÇ                 ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ
   ‚îÇ                 ‚îÇ                 ‚îÇ              ‚îÇ            ‚îÇ
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
```

---

## 8. Testing Strategy

### 8.1 Unit Tests

**File:** `tests/unit/nodes/registry/test_node.py`

**Test Coverage:**

- ‚úÖ NodeBridgeRegistry initialization
- ‚úÖ Introspection event deserialization
- ‚úÖ Dual registration orchestration logic
- ‚è≥ Consul registration method (pending implementation)
- ‚è≥ PostgreSQL registration method (pending implementation)
- ‚úÖ Circuit breaker behavior
- ‚úÖ TTL cache operations
- ‚úÖ Cleanup task execution

**Run Tests:**

```bash
pytest tests/unit/nodes/registry/ -v
```

### 8.2 Integration Tests

**File:** `tests/integration/test_two_way_registration_e2e.py`

**Test Coverage:**

- ‚úÖ End-to-end introspection flow
- ‚è≥ Kafka message production/consumption (pending)
- ‚è≥ Consul registration verification (pending)
- ‚è≥ PostgreSQL persistence verification (pending)
- ‚è≥ Service discovery queries (pending)

**Run Tests:**

```bash
pytest tests/integration/test_two_way_registration_e2e.py -v
```

### 8.3 Load Tests

**File:** `tests/load/test_introspection_load.py`

**Test Scenarios:**

- ‚è≥ 100 concurrent introspection broadcasts
- ‚è≥ 1000+ registrations per second
- ‚è≥ Memory usage under load
- ‚è≥ Circuit breaker under failure conditions

**Run Tests:**

```bash
pytest tests/load/test_introspection_load.py -v --load
```

---

## 9. Performance Targets

### 9.1 NodeBridgeRegistry Performance

| Metric | Target | Current | Status |
|--------|--------|---------|--------|
| Registration Latency | <100ms | Unknown | ‚è≥ Pending |
| Throughput | 100+ reg/sec | Unknown | ‚è≥ Pending |
| Memory Usage | <512MB | Cache-only | ‚è≥ Pending |
| Cache Hit Rate | >80% | N/A | ‚è≥ Pending |
| Circuit Breaker Response | <1ms | Implemented | ‚úÖ Complete |

### 9.2 IntrospectionMixin Performance

| Metric | Target | Current | Status |
|--------|--------|---------|--------|
| Introspection Extraction | <50ms | Cached | ‚úÖ Complete |
| Broadcast Latency | <100ms | Stubbed | ‚è≥ Pending |
| Heartbeat Overhead | <0.1% CPU | Unknown | ‚è≥ Pending |
| Event Size | <2KB | ~1-2KB | ‚úÖ Complete |

### 9.3 Consul Performance

| Metric | Target | Current | Status |
|--------|--------|---------|--------|
| Service Registration | <50ms | N/A | ‚è≥ Pending |
| Health Check Latency | <5s | Configured | ‚úÖ Complete |
| DNS Query Latency | <10ms | N/A | ‚è≥ Pending |
| Service Discovery | <20ms | N/A | ‚è≥ Pending |

---

## 10. Related Documentation

### 10.1 Architecture Documentation

- **[Dual Registration Architecture](../architecture/DUAL_REGISTRATION_ARCHITECTURE.md)** - Complete system architecture
- **[Node Introspection Integration](../architecture/two-way-registration/NODE_INTROSPECTION_INTEGRATION.md)** - Full introspection guide
- **[Service Registration Status](../architecture/SERVICE_REGISTRATION_STATUS.md)** - Current implementation status
- **[Introspection Quick Reference](../architecture/two-way-registration/INTROSPECTION_QUICK_REFERENCE.md)** - Quick reference card

### 10.2 Planning Documentation

- **[MVP Registry Self-Registration](../planning/MVP_REGISTRY_SELF_REGISTRATION.md)** - Phase 1a implementation plan
- **[Post-MVP Production Enhancements](../planning/POST_MVP_PRODUCTION_ENHANCEMENTS.md)** - Production roadmap

### 10.3 Implementation Files

- **NodeBridgeRegistry:** `src/omninode_bridge/nodes/registry/v1_0_0/node.py`
- **IntrospectionMixin:** `src/omninode_bridge/nodes/mixins/introspection_mixin.py`
- **Consul Client:** `src/omninode_bridge/services/metadata_stamping/registry/consul_client.py`
- **Service Discovery Contract:** `src/omninode_bridge/nodes/registry/v1_0_0/contracts/service_discovery.yaml`
- **PostgreSQL Migration:** `migrations/005_create_node_registrations.sql`

### 10.4 Testing Files

- **Unit Tests:** `tests/unit/nodes/registry/test_node.py`
- **Integration Tests:** `tests/integration/test_two_way_registration_e2e.py`
- **Load Tests:** `tests/load/test_introspection_load.py`
- **Introspection Tests:** `tests/test_introspection_mixin.py`

---

## 11. Conclusions and Recommendations

### 11.1 Key Findings Summary

1. **Architecture is Complete and Well-Documented**
   - Comprehensive two-way registration design
   - Production-ready patterns (circuit breaker, TTL cache, atomic registration)
   - Extensive documentation with clear examples

2. **Implementation is Partially Complete**
   - Core orchestration logic implemented
   - IntrospectionMixin fully functional
   - Backend integrations (Consul, PostgreSQL, Kafka) stubbed and pending

3. **Critical Gaps Preventing Operation**
   - NodeBridgeRegistry container not deployed
   - PostgreSQL migration not applied
   - Backend integration methods not implemented

4. **Clear Path to Completion**
   - Well-defined remediation steps
   - Estimated 3-4 days for full implementation
   - Phased approach with clear milestones

### 11.2 Immediate Next Steps (Priority Order)

**Week 1: Infrastructure & Deployment (Days 1-2)**

1. ‚úÖ Apply PostgreSQL migration 005 (30 minutes)
2. ‚úÖ Verify/create Kafka topics (15 minutes)
3. ‚úÖ Configure environment variables (15 minutes)
4. ‚úÖ Create Docker container configuration (1 hour)
5. ‚úÖ Deploy NodeBridgeRegistry container (30 minutes)

**Week 1: Backend Integration (Days 3-4)**

6. üî¥ Implement Consul registration method (4 hours)
7. üî¥ Implement PostgreSQL registration method (4 hours)
8. üî¥ Implement Kafka event publishing (2 hours)
9. üî¥ Implement atomic dual registration (2 hours)
10. üî¥ Add error handling and circuit breaker integration (2 hours)

**Week 2: Testing & Validation (Days 5-7)**

11. ‚ö†Ô∏è Write unit tests for backend methods (4 hours)
12. ‚ö†Ô∏è Write integration tests for end-to-end flow (4 hours)
13. ‚ö†Ô∏è Perform manual testing and validation (4 hours)
14. ‚ö†Ô∏è Load testing and performance validation (4 hours)
15. ‚ö†Ô∏è Documentation updates (2 hours)

### 11.3 Success Criteria

**Functional Requirements:**

- [x] Architecture documented and reviewed
- [x] IntrospectionMixin integrated into nodes
- [ ] NodeBridgeRegistry deployed and operational
- [ ] Consul registration working
- [ ] PostgreSQL registration working
- [ ] End-to-end introspection flow operational
- [ ] Service discovery queries working
- [ ] Code generation orchestrator can resolve services

**Non-Functional Requirements:**

- [ ] Registration latency <100ms (p95)
- [ ] Throughput >100 registrations/second
- [ ] Memory usage <512MB under normal load
- [ ] Circuit breaker operational under failures
- [ ] Health checks passing for all services
- [ ] 90%+ test coverage for new code

### 11.4 Risk Assessment

**Low Risk:**

- ‚úÖ Architecture is sound and well-tested in similar systems
- ‚úÖ IntrospectionMixin is production-ready
- ‚úÖ Infrastructure (Consul, PostgreSQL, Kafka) is operational

**Medium Risk:**

- ‚ö†Ô∏è Backend integration complexity
- ‚ö†Ô∏è Atomic transaction rollback logic
- ‚ö†Ô∏è Performance under high load unknown

**High Risk:**

- ‚ùå Timeline depends on backend integration work
- ‚ùå Service discovery may reveal additional issues
- ‚ùå Production deployment requires security hardening

**Mitigation Strategies:**

1. **Phased Implementation**: Deploy and test each component independently
2. **Fallback Strategy**: Cache-only mode operational as fallback
3. **Monitoring**: Comprehensive logging and metrics from day one
4. **Circuit Breakers**: Fail gracefully on backend failures

### 11.5 Long-Term Recommendations

**Post-MVP Enhancements (Phase 1b - Security):**

- Implement SPIFFE-based identity and trust
- Add cryptographic verification for introspection events
- Implement bootstrap controller with CA
- Add Consul ACLs and mTLS

**Post-MVP Enhancements (Phase 1c - Robustness):**

- Add lease semantics with TTL-based expiration
- Implement tombstone events for node removal
- Create topology diff stream for incremental updates
- Add service mesh integration (Consul Connect)

**Post-MVP Enhancements (Phase 2 - Multi-Tenancy):**

- Implement namespace isolation
- Add policy engine for authorization
- Create multi-network federation support
- Implement cross-datacenter replication

**Documentation Reference:** `docs/planning/POST_MVP_PRODUCTION_ENHANCEMENTS.md`

---

## Appendix A: Environment Setup Checklist

### Prerequisites

- [ ] Docker and Docker Compose installed
- [ ] Python 3.11+ with Poetry
- [ ] Access to remote infrastructure (192.168.86.200)
- [ ] PostgreSQL client tools (psql)
- [ ] Kafka client tools (rpk)

### Infrastructure Verification

- [ ] Consul accessible at http://192.168.86.200:28500
- [ ] PostgreSQL accessible at 192.168.86.200:5436
- [ ] Redpanda accessible at 192.168.86.200:9092
- [ ] All containers running and healthy

### Configuration

- [ ] Environment variables configured
- [ ] PostgreSQL password set securely
- [ ] Consul token configured (if ACLs enabled)
- [ ] Kafka topics created
- [ ] PostgreSQL migration applied

### Deployment

- [ ] NodeBridgeRegistry container built
- [ ] NodeBridgeRegistry container running
- [ ] Health check endpoint responding
- [ ] Background tasks operational

### Validation

- [ ] Services broadcasting introspection
- [ ] Kafka messages flowing
- [ ] Consul registrations appearing
- [ ] PostgreSQL records created
- [ ] Service discovery working

---

**Document Version:** 1.0.0
**Research Date:** October 30, 2025
**Research Method:** Comprehensive Codebase Analysis
**Correlation ID:** e3e1196c-ff94-47d8-b91b-88cb58b81216
**Status:** ‚úÖ Research Complete - Implementation Roadmap Provided

---

**Next Action:** Begin Phase 1 (Infrastructure Setup) with PostgreSQL migration application.
