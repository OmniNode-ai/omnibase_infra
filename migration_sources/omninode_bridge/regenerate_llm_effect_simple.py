#!/usr/bin/env python3
"""
Regenerate llm_effect node with mixin-enhanced code generation - Simplified Version.

Wave 4 Phase 1: First high-priority node regeneration.
Bypasses contract parsing and generates directly from requirements.
"""

import asyncio
import logging
from pathlib import Path
from uuid import uuid4

from src.omninode_bridge.codegen import CodeGenerationService
from src.omninode_bridge.codegen.prd_analyzer import ModelPRDRequirements

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


async def regenerate_llm_effect_node():
    """
    Regenerate llm_effect node with mixin enhancements.

    Simplified approach:
    1. Create requirements directly
    2. Generate with mixins enabled
    3. Compare and validate
    """
    print("=" * 80)
    print("ðŸš€ Regenerating llm_effect Node (Wave 4 Phase 1 - Simplified)")
    print("=" * 80)

    # Paths
    node_dir = Path("src/omninode_bridge/nodes/llm_effect/v1_0_0")
    backup_dir = Path(str(node_dir) + ".backup")
    output_dir = node_dir / "generated"

    print(f"\nðŸ“¦ Output: {output_dir}")
    print(f"ðŸ’¾ Backup: {backup_dir}")

    # Step 1: Create requirements directly
    print("\n" + "=" * 80)
    print("Step 1: Create Requirements for LLM Effect Node")
    print("=" * 80)

    requirements = ModelPRDRequirements(
        node_type="effect",
        service_name="llm_effect",
        domain="ai_services",
        business_description=(
            "LLM Effect Node for multi-tier LLM generation with Z.ai integration. "
            "Supports CLOUD_FAST (GLM-4.5) tier with 128K context window. "
            "Includes circuit breaker, retry logic, token tracking, and cost management."
        ),
        operations=[
            "generate_text",  # Main LLM generation operation
            "calculate_cost",  # Token cost calculation
            "track_usage",  # Token usage tracking
        ],
        features=[
            # Core features
            "Multi-tier LLM support (LOCAL, CLOUD_FAST, CLOUD_PREMIUM)",
            "Z.ai API integration (Anthropic-compatible endpoint)",
            "GLM-4.5 model support (PRIMARY tier)",
            # Resilience patterns
            "Circuit breaker pattern for fault tolerance",
            "Retry logic with exponential backoff",
            "HTTP client with connection pooling",
            # Tracking and metrics
            "Token usage tracking (input/output/total)",
            "Cost tracking with sub-cent accuracy",
            "Comprehensive metrics collection via MixinMetrics",
            "Performance monitoring (latency, throughput)",
            # Health and observability
            "Health checks via MixinHealthCheck",
            "Z.ai API health monitoring",
            "Structured logging with correlation tracking",
            "OpenTelemetry tracing support",
            # Configuration
            "Environment-based credentials (ZAI_API_KEY)",
            "Configurable timeouts and thresholds",
            "Per-tier pricing configuration",
        ],
        integrations=[
            "Z.ai API (https://api.z.ai/api/anthropic)",
            "omnibase_core ModelCircuitBreaker",
            "httpx AsyncClient for HTTP operations",
            "PostgreSQL for metrics persistence (via MixinMetrics)",
        ],
        performance_requirements={
            "latency_p95_ms": 3000,  # 3 seconds for CLOUD_FAST
            "throughput_rps": 10,  # 10 requests per second
            "max_memory_mb": 512,
            "max_cpu_percent": 25,
        },
        quality_requirements={
            "test_coverage_percent": 80,
            "code_complexity_max": 10,
            "documentation_required": True,
        },
        extraction_confidence=0.95,  # High confidence - manually crafted requirements
    )

    print("âœ… Requirements created:")
    print(f"   Node Type: {requirements.node_type}")
    print(f"   Service: {requirements.service_name}")
    print(f"   Domain: {requirements.domain}")
    print(f"   Operations: {', '.join(requirements.operations)}")
    print(f"   Features: {len(requirements.features)}")
    print("   Mixin support: enabled (MixinMetrics + MixinHealthCheck)")

    # Step 2: Initialize service and generate
    print("\n" + "=" * 80)
    print("Step 2: Generate Node with Mixin Enhancement")
    print("=" * 80)

    service = CodeGenerationService()
    correlation_id = uuid4()

    print("â³ Generating code...")
    print("   Strategy: auto")
    print("   Mixins: enabled")
    print("   Validation: none")
    print("   LLM: disabled")
    print(f"   Correlation ID: {correlation_id}")

    result = await service.generate_node(
        requirements=requirements,
        output_directory=output_dir,
        strategy="auto",
        enable_llm=False,  # LLM strategies not available without ZAI_API_KEY
        enable_mixins=True,
        validation_level="none",  # Skip validation to avoid contract issues
        run_tests=False,  # Run tests separately
        correlation_id=correlation_id,
    )

    # Step 3: Display results
    print("\n" + "=" * 80)
    print("Step 3: Generation Results")
    print("=" * 80)

    print("\nâœ… Generation complete!")
    print(f"   Node Name: {result.artifacts.node_name}")
    print(f"   Strategy: {result.strategy_used.value}")
    print(f"   Time: {result.generation_time_ms:.0f}ms")
    print(f"   Validation: {'âœ… PASSED' if result.validation_passed else 'âŒ FAILED'}")
    print(f"   LLM Used: {'Yes' if result.llm_used else 'No'}")

    if result.mixins_applied:
        print(f"\nâœ… Mixins Applied ({len(result.mixins_applied)}):")
        for mixin in result.mixins_applied:
            print(f"   - {mixin}")

    # List generated files
    all_files = result.artifacts.get_all_files()
    print(f"\nðŸ“¦ Generated {len(all_files)} files:")
    for filename in sorted(all_files.keys()):
        file_size = len(all_files[filename])
        print(f"   - {filename} ({file_size:,} bytes)")

    # Write files
    print(f"\nðŸ’¾ Writing files to {output_dir}")
    output_dir.mkdir(parents=True, exist_ok=True)

    for filename, content in all_files.items():
        file_path = output_dir / filename
        file_path.parent.mkdir(parents=True, exist_ok=True)
        file_path.write_text(content)
        print(f"   âœ… {filename}")

    print(f"\nâœ… Files written to: {output_dir.absolute()}")

    # Step 4: Validation details
    if result.validation_errors:
        print(f"\nâš ï¸  Validation Errors ({len(result.validation_errors)}):")
        for error in result.validation_errors[:10]:
            print(f"   - {error}")

    if result.validation_warnings:
        print(f"\nâš ï¸  Validation Warnings ({len(result.validation_warnings)}):")
        for warning in result.validation_warnings[:10]:
            print(f"   - {warning}")

    # Step 5: LOC comparison
    print("\n" + "=" * 80)
    print("Step 4: LOC Comparison")
    print("=" * 80)

    original_node = backup_dir / "node.py"
    generated_node = output_dir / "node.py"

    if original_node.exists() and generated_node.exists():
        original_loc = count_code_loc(original_node)
        generated_loc = count_code_loc(generated_node)
        reduction = original_loc - generated_loc
        percentage = (reduction / original_loc) * 100 if original_loc > 0 else 0

        print("\nðŸ“Š LOC Metrics:")
        print(f"   Original: {original_loc} lines")
        print(f"   Generated: {generated_loc} lines")
        print(f"   Reduction: {reduction} lines ({percentage:.1f}%)")
        print("   Target: 26-31% reduction (92-110 lines)")

        if 26 <= percentage <= 35:
            print("   Status: âœ… SUCCESS - Within target range")
        elif percentage > 0:
            print("   Status: âš ï¸  REVIEW - Outside target range but positive")
        else:
            print("   Status: âŒ FAILURE - No reduction achieved")
    else:
        print("âš ï¸  Could not perform LOC comparison (files not found)")
        if not original_node.exists():
            print(f"   Missing: {original_node}")
        if not generated_node.exists():
            print(f"   Missing: {generated_node}")

    # Summary
    print("\n" + "=" * 80)
    print("Summary")
    print("=" * 80)

    print("\nâœ… Regeneration Complete!")
    print(f"\nðŸ“ Generated files: {output_dir}")
    print(f"ðŸ“ Original backup: {backup_dir}")
    print("\nðŸ” Next Steps:")
    print(f"   1. Review generated code: {output_dir / 'node.py'}")
    print(f"   2. Compare with original: {backup_dir / 'node.py'}")
    print("   3. Check mixin integration")
    print("   4. Run tests: pytest tests/unit/nodes/llm_effect/")
    print("   5. If tests pass, replace original with generated code")

    return 0


def count_code_loc(file_path: Path) -> int:
    """
    Count LOC excluding blank lines, comments, and docstrings.

    Args:
        file_path: Path to Python file

    Returns:
        Number of code lines
    """
    with open(file_path) as f:
        lines = f.readlines()

    code_lines = 0
    in_docstring = False

    for line in lines:
        stripped = line.strip()

        # Skip blank lines
        if not stripped:
            continue

        # Handle docstrings
        if '"""' in stripped or "'''" in stripped:
            if stripped.count('"""') == 2 or stripped.count("'''") == 2:
                # Single-line docstring
                continue
            in_docstring = not in_docstring
            continue

        if in_docstring:
            continue

        # Skip comment-only lines
        if stripped.startswith("#"):
            continue

        code_lines += 1

    return code_lines


async def main():
    """Main entry point."""
    try:
        exit_code = await regenerate_llm_effect_node()
        return exit_code
    except Exception as e:
        logger.error(f"Regeneration failed: {e}", exc_info=True)
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    exit(exit_code)
