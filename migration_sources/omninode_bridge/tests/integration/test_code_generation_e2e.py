#!/usr/bin/env python3
"""
End-to-end integration tests for Phase 3 code generation pipeline.

Tests complete pipeline flow from contract to generated artifacts with all
Phase 3 components:
- Template variant selection
- Pattern matching
- Mixin recommendations
- LLM enhancement (mocked)
- Contract processing with subcontracts

Performance Targets:
- Full generation: <20s per node
- Variant selection: <5ms
- Pattern matching: <10ms
- Context building: <50ms

Quality Targets:
- >95% correct template selection
- >90% pattern match relevance
- Code compiles successfully
- ONEX v2.0 compliance
"""

import ast
import logging
import time
from pathlib import Path
from typing import Any

import pytest
import yaml

from omninode_bridge.codegen.context_builder import EnhancedContextBuilder
from omninode_bridge.codegen.mixins.conflict_resolver import ConflictResolver
from omninode_bridge.codegen.mixins.mixin_recommender import MixinRecommender
from omninode_bridge.codegen.mixins.requirements_analyzer import RequirementsAnalyzer
from omninode_bridge.codegen.models_contract import EnumTemplateVariant
from omninode_bridge.codegen.pattern_library import ProductionPatternLibrary
from omninode_bridge.codegen.pipeline import CodeGenerationPipeline
from omninode_bridge.codegen.template_selector import TemplateSelector

logger = logging.getLogger(__name__)


# ============================================================================
# Fixtures
# ============================================================================


@pytest.fixture
def contracts_dir():
    """Get contracts directory."""
    return Path(__file__).parent.parent / "fixtures" / "contracts"


@pytest.fixture
def load_contract(contracts_dir):
    """Factory to load test contracts."""

    def _load(filename: str) -> dict[str, Any]:
        contract_path = contracts_dir / filename
        with open(contract_path) as f:
            return yaml.safe_load(f)

    return _load


@pytest.fixture
def temp_output_dir(tmp_path):
    """Create temporary output directory."""
    output_dir = tmp_path / "generated_nodes"
    output_dir.mkdir()
    return output_dir


@pytest.fixture
def template_selector():
    """Create TemplateSelector instance."""
    return TemplateSelector()


@pytest.fixture
def pattern_library():
    """Create ProductionPatternLibrary instance."""
    return ProductionPatternLibrary()


@pytest.fixture
def requirements_analyzer():
    """Create RequirementsAnalyzer instance."""
    return RequirementsAnalyzer()


@pytest.fixture
def mixin_recommender():
    """Create MixinRecommender instance."""
    return MixinRecommender()


@pytest.fixture
def conflict_resolver():
    """Create ConflictResolver instance."""
    return ConflictResolver()


@pytest.fixture
def context_builder():
    """Create EnhancedContextBuilder instance."""
    return EnhancedContextBuilder()


@pytest.fixture
def pipeline(tmp_path):
    """Create CodeGenerationPipeline with LLM disabled."""
    return CodeGenerationPipeline(
        template_dir=None,  # Use defaults
        enable_llm=False,  # Disable for predictable tests
        enable_validation=False,  # Speed up tests
    )


@pytest.fixture
def mock_llm_response():
    """Mock LLM response for testing."""
    return """
async def execute_effect(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
    \"\"\"
    Execute the effect operation.

    Auto-generated by LLM enhancement.
    \"\"\"
    logger.info("Executing effect operation")

    # Mock implementation
    result = {
        "success": True,
        "data": input_data,
        "timestamp": time.time()
    }

    return result
"""


# ============================================================================
# E2E Test Class: Complete Pipeline
# ============================================================================


@pytest.mark.integration
class TestCodeGenerationE2E:
    """End-to-end tests for complete code generation pipeline."""

    @pytest.mark.asyncio
    async def test_generate_minimal_effect_node_e2e(
        self, pipeline, load_contract, temp_output_dir
    ):
        """
        Test generating minimal effect node end-to-end.

        Validates:
        - Minimal template variant selected
        - No mixins recommended
        - Basic code structure generated
        - Code compiles successfully
        """
        # Load minimal contract
        contract = load_contract("minimal_effect_contract.yaml")

        start_time = time.perf_counter()

        # Generate node
        result = await pipeline.generate_node(
            node_type="effect",
            version="v1_0_0",
            requirements=contract,
            output_dir=temp_output_dir,
        )

        generation_time = (time.perf_counter() - start_time) * 1000

        # Assertions
        assert result is not None, "Generation failed"
        assert result.node_name is not None, "Node name not set"
        assert (
            generation_time < 20000
        ), f"Generation took {generation_time:.2f}ms (target: <20s)"

        # Verify artifacts exist
        assert (temp_output_dir / "node.py").exists(), "node.py not generated"

        # Verify code compiles
        generated_code = (temp_output_dir / "node.py").read_text()
        try:
            ast.parse(generated_code)
        except SyntaxError as e:
            pytest.fail(f"Generated code has syntax errors: {e}")

        logger.info(f"✅ Minimal effect generation: {generation_time:.2f}ms")

    @pytest.mark.asyncio
    async def test_generate_standard_effect_node_e2e(
        self, pipeline, load_contract, temp_output_dir
    ):
        """
        Test generating standard effect node with mixins.

        Validates:
        - Standard template variant selected
        - Core mixins included
        - Proper imports and structure
        - Code compiles successfully
        """
        contract = load_contract("standard_effect_contract.yaml")

        start_time = time.perf_counter()
        result = await pipeline.generate_node(
            node_type="effect",
            version="v1_0_0",
            requirements=contract,
            output_dir=temp_output_dir,
        )
        generation_time = (time.perf_counter() - start_time) * 1000

        assert result is not None
        assert generation_time < 20000

        # Verify code quality
        generated_code = (temp_output_dir / "node.py").read_text()
        ast.parse(generated_code)  # Syntax check

        # Verify standard features present
        assert "async def" in generated_code, "No async methods found"
        assert "from omnibase_core" in generated_code, "Missing omnibase imports"

        logger.info(f"✅ Standard effect generation: {generation_time:.2f}ms")

    @pytest.mark.asyncio
    async def test_generate_production_orchestrator_e2e(
        self, pipeline, load_contract, temp_output_dir
    ):
        """
        Test generating production-grade orchestrator with all subcontracts.

        Validates:
        - Production template variant selected
        - All 6 subcontract types processed
        - FSM, events, caching, routing, state management, aggregation
        - Comprehensive error handling
        - Production patterns applied
        """
        contract = load_contract("production_orchestrator_contract.yaml")

        start_time = time.perf_counter()
        result = await pipeline.generate_node(
            node_type="orchestrator",
            version="v1_0_0",
            requirements=contract,
            output_dir=temp_output_dir,
        )
        generation_time = (time.perf_counter() - start_time) * 1000

        assert result is not None
        assert generation_time < 20000

        generated_code = (temp_output_dir / "node.py").read_text()
        ast.parse(generated_code)

        # Verify production features
        assert (
            "class NodePaymentOrchestratorOrchestrator" in generated_code
            or "Orchestrator" in generated_code
        ), "Orchestrator class not found"

        logger.info(f"✅ Production orchestrator generation: {generation_time:.2f}ms")

    @pytest.mark.asyncio
    async def test_generate_database_heavy_effect_e2e(
        self, pipeline, load_contract, temp_output_dir
    ):
        """
        Test generating database-heavy effect node.

        Validates:
        - Database_heavy template variant selected
        - Connection pooling patterns included
        - Transaction management present
        - Query optimization patterns
        """
        contract = load_contract("database_adapter_effect.yaml")

        start_time = time.perf_counter()
        result = await pipeline.generate_node(
            node_type="effect",
            version="v1_0_0",
            requirements=contract,
            output_dir=temp_output_dir,
        )
        generation_time = (time.perf_counter() - start_time) * 1000

        assert result is not None
        assert generation_time < 20000

        generated_code = (temp_output_dir / "node.py").read_text()
        ast.parse(generated_code)

        logger.info(f"✅ Database-heavy effect generation: {generation_time:.2f}ms")

    @pytest.mark.asyncio
    async def test_generate_api_heavy_effect_e2e(
        self, pipeline, load_contract, temp_output_dir
    ):
        """
        Test generating API-heavy effect node.

        Validates:
        - API_heavy template variant selected
        - Retry logic patterns included
        - Circuit breaker implementation
        - Rate limiting present
        """
        contract = load_contract("api_client_effect.yaml")

        start_time = time.perf_counter()
        result = await pipeline.generate_node(
            node_type="effect",
            version="v1_0_0",
            requirements=contract,
            output_dir=temp_output_dir,
        )
        generation_time = (time.perf_counter() - start_time) * 1000

        assert result is not None
        assert generation_time < 20000

        generated_code = (temp_output_dir / "node.py").read_text()
        ast.parse(generated_code)

        logger.info(f"✅ API-heavy effect generation: {generation_time:.2f}ms")

    @pytest.mark.asyncio
    async def test_generate_kafka_heavy_effect_e2e(
        self, pipeline, load_contract, temp_output_dir
    ):
        """
        Test generating Kafka-heavy effect node.

        Validates:
        - Kafka_heavy template variant selected
        - Consumer/producer patterns included
        - Event serialization handling
        - Offset management present
        """
        contract = load_contract("kafka_consumer_effect.yaml")

        start_time = time.perf_counter()
        result = await pipeline.generate_node(
            node_type="effect",
            version="v1_0_0",
            requirements=contract,
            output_dir=temp_output_dir,
        )
        generation_time = (time.perf_counter() - start_time) * 1000

        assert result is not None
        assert generation_time < 20000

        generated_code = (temp_output_dir / "node.py").read_text()
        ast.parse(generated_code)

        logger.info(f"✅ Kafka-heavy effect generation: {generation_time:.2f}ms")

    @pytest.mark.asyncio
    async def test_generate_ml_inference_compute_e2e(
        self, pipeline, load_contract, temp_output_dir
    ):
        """
        Test generating ML inference compute node.

        Validates:
        - ML_inference template variant selected
        - Model loading patterns included
        - Batch inference support
        - Feature preprocessing present
        """
        contract = load_contract("ml_inference_compute.yaml")

        start_time = time.perf_counter()
        result = await pipeline.generate_node(
            node_type="compute",
            version="v1_0_0",
            requirements=contract,
            output_dir=temp_output_dir,
        )
        generation_time = (time.perf_counter() - start_time) * 1000

        assert result is not None
        assert generation_time < 20000

        generated_code = (temp_output_dir / "node.py").read_text()
        ast.parse(generated_code)

        logger.info(f"✅ ML inference compute generation: {generation_time:.2f}ms")

    @pytest.mark.asyncio
    async def test_generate_analytics_reducer_e2e(
        self, pipeline, load_contract, temp_output_dir
    ):
        """
        Test generating analytics reducer node.

        Validates:
        - Analytics_reducer template variant selected
        - Aggregation patterns included
        - Window management present
        - State checkpointing
        """
        contract = load_contract("analytics_reducer.yaml")

        start_time = time.perf_counter()
        result = await pipeline.generate_node(
            node_type="reducer",
            version="v1_0_0",
            requirements=contract,
            output_dir=temp_output_dir,
        )
        generation_time = (time.perf_counter() - start_time) * 1000

        assert result is not None
        assert generation_time < 20000

        generated_code = (temp_output_dir / "node.py").read_text()
        ast.parse(generated_code)

        logger.info(f"✅ Analytics reducer generation: {generation_time:.2f}ms")

    @pytest.mark.asyncio
    async def test_generate_workflow_orchestrator_e2e(
        self, pipeline, load_contract, temp_output_dir
    ):
        """
        Test generating workflow orchestrator node.

        Validates:
        - Workflow_orchestrator template variant selected
        - Parallel execution patterns
        - Conditional routing
        - Saga pattern for compensation
        """
        contract = load_contract("workflow_orchestrator.yaml")

        start_time = time.perf_counter()
        result = await pipeline.generate_node(
            node_type="orchestrator",
            version="v1_0_0",
            requirements=contract,
            output_dir=temp_output_dir,
        )
        generation_time = (time.perf_counter() - start_time) * 1000

        assert result is not None
        assert generation_time < 20000

        generated_code = (temp_output_dir / "node.py").read_text()
        ast.parse(generated_code)

        logger.info(f"✅ Workflow orchestrator generation: {generation_time:.2f}ms")


# ============================================================================
# E2E Test Class: Pipeline Workflow Components
# ============================================================================


@pytest.mark.integration
class TestCodeGenerationWorkflow:
    """Integration tests for generation workflow component interactions."""

    @pytest.mark.asyncio
    async def test_workflow_variant_selection(self, template_selector, load_contract):
        """
        Test variant selection in workflow context.

        Validates:
        - Variant selection responds to contract complexity
        - Confidence scoring is accurate
        - Selection time meets <5ms target
        """
        contracts_to_test = [
            ("minimal_effect_contract.yaml", EnumTemplateVariant.MINIMAL),
            ("standard_effect_contract.yaml", EnumTemplateVariant.STANDARD),
            ("production_orchestrator_contract.yaml", EnumTemplateVariant.PRODUCTION),
        ]

        for contract_file, expected_variant in contracts_to_test:
            contract = load_contract(contract_file)

            start_time = time.perf_counter()
            selection = template_selector.select_template(
                requirements=contract,
                node_type=contract.get("node_type", "effect"),
            )
            selection_time = (time.perf_counter() - start_time) * 1000

            # Validate selection
            assert (
                selection.variant is not None
            ), f"No variant selected for {contract_file}"
            assert selection.confidence > 0.0, "Confidence score not set"
            assert (
                selection_time < 5.0
            ), f"Selection took {selection_time:.2f}ms (target: <5ms)"

            logger.info(
                f"✅ Variant selection for {contract_file}: "
                f"{selection.variant} (confidence: {selection.confidence:.2f}, "
                f"time: {selection_time:.2f}ms)"
            )

    @pytest.mark.asyncio
    async def test_workflow_pattern_matching(self, pattern_library, load_contract):
        """
        Test pattern matching in workflow context.

        Validates:
        - Patterns matched based on contract features
        - Relevance scoring accurate
        - Match time meets <10ms target
        """
        contract = load_contract("production_orchestrator_contract.yaml")

        start_time = time.perf_counter()
        patterns = pattern_library.match_patterns(
            contract=contract,
            node_type="orchestrator",
            max_results=10,
        )
        match_time = (time.perf_counter() - start_time) * 1000

        assert len(patterns) > 0, "No patterns matched"
        assert (
            match_time < 10.0
        ), f"Pattern matching took {match_time:.2f}ms (target: <10ms)"

        # Verify relevance scores
        for pattern_match in patterns:
            assert (
                0.0 <= pattern_match.relevance_score <= 1.0
            ), f"Invalid relevance score: {pattern_match.relevance_score}"

        logger.info(
            f"✅ Pattern matching: {len(patterns)} patterns matched in {match_time:.2f}ms"
        )

    @pytest.mark.asyncio
    async def test_workflow_mixin_selection(
        self, requirements_analyzer, mixin_recommender, conflict_resolver, load_contract
    ):
        """
        Test mixin selection workflow.

        Validates:
        - Requirements analysis extracts features correctly
        - Mixin recommendations are relevant
        - Conflicts resolved properly
        """
        contract = load_contract("production_orchestrator_contract.yaml")

        # Analyze requirements
        analysis = requirements_analyzer.analyze(contract)
        assert analysis is not None, "Requirements analysis failed"

        # Get recommendations
        recommendations = mixin_recommender.recommend(analysis)
        assert len(recommendations) > 0, "No mixins recommended"

        # Resolve conflicts
        resolved = conflict_resolver.resolve(recommendations)
        assert resolved is not None, "Conflict resolution failed"

        logger.info(
            f"✅ Mixin selection: {len(recommendations)} recommended, "
            f"{len(resolved)} after conflict resolution"
        )

    @pytest.mark.asyncio
    async def test_workflow_context_building(
        self, context_builder, pattern_library, load_contract
    ):
        """
        Test context building for LLM enhancement.

        Validates:
        - Context includes contract metadata
        - Patterns properly formatted
        - Build time meets <50ms target
        """
        contract = load_contract("production_orchestrator_contract.yaml")
        patterns = pattern_library.match_patterns(
            contract=contract,
            node_type="orchestrator",
            max_results=5,
        )

        start_time = time.perf_counter()
        context = context_builder.build_context(
            contract=contract,
            node_type="orchestrator",
            patterns=patterns,
            operation_name="execute_orchestration",
        )
        build_time = (time.perf_counter() - start_time) * 1000

        assert context is not None, "Context building failed"
        assert len(context) > 0, "Context is empty"
        assert (
            build_time < 50.0
        ), f"Context building took {build_time:.2f}ms (target: <50ms)"

        logger.info(f"✅ Context building: {len(context)} chars in {build_time:.2f}ms")


# ============================================================================
# E2E Test Class: Code Quality Validation
# ============================================================================


@pytest.mark.integration
class TestCodeGenerationQuality:
    """Integration tests for generated code quality."""

    @pytest.mark.asyncio
    async def test_generated_code_syntax_validation(
        self, pipeline, load_contract, temp_output_dir
    ):
        """
        Test generated code has valid Python syntax for all templates.
        """
        contracts = [
            "minimal_effect_contract.yaml",
            "standard_effect_contract.yaml",
            "database_adapter_effect.yaml",
            "api_client_effect.yaml",
        ]

        for contract_file in contracts:
            contract = load_contract(contract_file)
            output_dir = temp_output_dir / contract_file.replace(".yaml", "")
            output_dir.mkdir()

            result = await pipeline.generate_node(
                node_type=contract.get("node_type", "effect"),
                version="v1_0_0",
                requirements=contract,
                output_dir=output_dir,
            )

            assert result is not None, f"Generation failed for {contract_file}"

            # Verify syntax
            generated_code = (output_dir / "node.py").read_text()
            try:
                ast.parse(generated_code)
                logger.info(f"✅ Syntax valid: {contract_file}")
            except SyntaxError as e:
                pytest.fail(f"Syntax error in {contract_file}: {e}")

    @pytest.mark.asyncio
    async def test_generated_code_imports(
        self, pipeline, load_contract, temp_output_dir
    ):
        """
        Test generated code has correct imports.
        """
        contract = load_contract("standard_effect_contract.yaml")

        result = await pipeline.generate_node(
            node_type="effect",
            version="v1_0_0",
            requirements=contract,
            output_dir=temp_output_dir,
        )

        assert result is not None

        generated_code = (temp_output_dir / "node.py").read_text()

        # Verify essential imports
        required_imports = [
            "from typing import",
            "import logging",
        ]

        for imp in required_imports:
            assert imp in generated_code, f"Missing import: {imp}"

        logger.info("✅ Generated code has correct imports")

    @pytest.mark.asyncio
    async def test_generated_code_structure(
        self, pipeline, load_contract, temp_output_dir
    ):
        """
        Test generated code has proper ONEX v2.0 structure.
        """
        contract = load_contract("production_orchestrator_contract.yaml")

        result = await pipeline.generate_node(
            node_type="orchestrator",
            version="v1_0_0",
            requirements=contract,
            output_dir=temp_output_dir,
        )

        assert result is not None

        generated_code = (temp_output_dir / "node.py").read_text()

        # Verify ONEX structure elements
        structural_elements = [
            "class Node",  # Node class
            "async def",  # Async methods
            "logger = logging.getLogger",  # Logging setup
        ]

        for element in structural_elements:
            assert element in generated_code, f"Missing structural element: {element}"

        logger.info("✅ Generated code has proper ONEX v2.0 structure")


if __name__ == "__main__":
    pytest.main([__file__, "-v", "--tb=short"])
