#!/usr/bin/env python3
"""
{{ node_name }} - ONEX v2.0 Reducer node for analytics aggregation.

{{ description }}

Features:
- Time-series aggregation
- Windowing ({{ window_size_seconds }}s windows)
- Percentile calculation (P50, P95, P99)
- Histogram generation
- Metric export

Performance Targets:
- Aggregation latency: < 10ms for 1000 items
- Throughput: 1000+ metrics/sec
- Memory: < 100MB
- Window accuracy: Â±1s

Contract: {{ contract_name }}
Node Type: REDUCER (Analytics)
"""

import asyncio
import logging
import time
from collections import defaultdict, deque
from datetime import UTC, datetime, timedelta
from typing import Any

from omnibase_core import EnumCoreErrorCode, ModelOnexError
from omnibase_core.enums.enum_log_level import EnumLogLevel as LogLevel
from omnibase_core.logging.structured import emit_log_event_sync as emit_log_event
from omnibase_core.models.contracts.model_contract_reducer import ModelContractReducer
from omnibase_core.models.core import ModelContainer
from omnibase_core.nodes.node_reducer import NodeReducer

from .models import {{ input_model }}, {{ output_model }}

OnexError = ModelOnexError
CoreErrorCode = EnumCoreErrorCode
logger = logging.getLogger(__name__)


class {{ node_class_name }}(NodeReducer):
    """{{ node_description }}

    Aggregation Configuration:
    - Window size: {{ window_size_seconds }}s
    - Percentiles: {{ percentiles }}
    - Histogram buckets: {{ histogram_buckets }}
    """

    def __init__(self, container: ModelContainer) -> None:
        super().__init__(container)
        self._window_size = timedelta(seconds={{ window_size_seconds }})
        self._metrics_buffer: defaultdict = defaultdict(deque)
        self._buffer_lock = asyncio.Lock()

        self._stats = {
            "metrics_aggregated": 0,
            "windows_processed": 0,
            "total_aggregation_time_ms": 0.0,
        }

    async def execute_reduction(
        self,
        contract: ModelContractReducer,
        streaming_data: list[Any],
    ) -> {{ output_model }}:
        """Execute analytics aggregation."""
        start_time = time.perf_counter()

        try:
            async with self._buffer_lock:
                # Add new metrics to buffer
                for item in streaming_data:
                    metric = {{ input_model }}(**item)
                    self._metrics_buffer[metric.metric_name].append(
                        (metric.timestamp, metric.value)
                    )
                    self._stats["metrics_aggregated"] += 1

                # Aggregate by window
                now = datetime.now(UTC)
                window_start = now - self._window_size

                aggregated = {}
                for metric_name, values in self._metrics_buffer.items():
                    # Filter to current window
                    window_values = [
                        v for ts, v in values
                        if ts >= window_start
                    ]

                    if window_values:
                        aggregated[metric_name] = self._calculate_stats(window_values)

                    # Clean old values
                    self._metrics_buffer[metric_name] = deque(
                        [(ts, v) for ts, v in values if ts >= window_start]
                    )

                self._stats["windows_processed"] += 1

            elapsed_ms = (time.perf_counter() - start_time) * 1000
            self._stats["total_aggregation_time_ms"] += elapsed_ms

            return {{ output_model }}(
                window_start=window_start,
                window_end=now,
                aggregated_metrics=aggregated,
                elapsed_ms=elapsed_ms,
            )

        except Exception as e:
            raise OnexError(
                error_code=CoreErrorCode.INTERNAL_ERROR,
                message=f"Aggregation failed: {str(e)}",
            ) from e

    def _calculate_stats(self, values: list[float]) -> dict[str, Any]:
        """Calculate statistics for a metric."""
        sorted_values = sorted(values)
        n = len(sorted_values)

        return {
            "count": n,
            "sum": sum(sorted_values),
            "mean": sum(sorted_values) / n,
            "min": sorted_values[0],
            "max": sorted_values[-1],
            "p50": sorted_values[int(n * 0.50)],
            "p95": sorted_values[int(n * 0.95)],
            "p99": sorted_values[int(n * 0.99)],
        }

    def get_metrics(self) -> dict[str, Any]:
        return self._stats
