"""
Performance optimization models for code generation workflows.

Provides data models for profiling results, optimization recommendations,
and performance analysis. Designed to achieve 2-3x speedup vs Phase 3.

Performance Targets:
- Overall speedup: 2-3x vs Phase 3 (measured)
- Template cache hit rate: 95%+ (from 85-95%)
- Parallel execution speedup: 3-4x (from 2.25x-4.17x)
- Memory overhead: <50MB
- Profiling overhead: <5%
"""

from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Optional, Union

from pydantic import BaseModel, Field


class OptimizationArea(str, Enum):
    """Optimization area categories."""

    TEMPLATE_CACHE = "template_cache"
    PARALLEL_EXECUTION = "parallel_execution"
    MEMORY = "memory"
    IO = "io"
    CPU = "cpu"
    NETWORK = "network"


class OptimizationPriority(str, Enum):
    """Optimization priority levels."""

    CRITICAL = "critical"  # >50% performance impact
    HIGH = "high"  # 20-50% performance impact
    MEDIUM = "medium"  # 10-20% performance impact
    LOW = "low"  # <10% performance impact


class ProfileMetricType(str, Enum):
    """Types of profiling metrics."""

    TIMING = "timing"
    MEMORY = "memory"
    IO = "io"
    CPU = "cpu"
    CACHE = "cache"
    THROUGHPUT = "throughput"


@dataclass
class ProfileResult:
    """
    Performance profiling result for a single operation.

    Tracks timing, memory, and bottleneck analysis for optimization.

    Attributes:
        operation_name: Name of the profiled operation
        total_time_ms: Total time across all calls
        call_count: Number of times operation was called
        avg_time_ms: Average time per call
        p50_ms: 50th percentile (median) time
        p95_ms: 95th percentile time
        p99_ms: 99th percentile time
        memory_mb: Peak memory usage in MB
        bottleneck_score: 0-1 score, higher = bigger bottleneck
        timestamp: When profiling was performed
        metadata: Additional profiling metadata
    """

    operation_name: str
    total_time_ms: float
    call_count: int
    avg_time_ms: float
    p50_ms: float
    p95_ms: float
    p99_ms: float
    memory_mb: float
    bottleneck_score: float
    timestamp: datetime = field(default_factory=datetime.utcnow)
    metadata: dict[str, Any] = field(default_factory=dict)

    def __post_init__(self):
        """Validate bottleneck score range."""
        if not 0.0 <= self.bottleneck_score <= 1.0:
            raise ValueError(
                f"bottleneck_score must be 0-1, got {self.bottleneck_score}"
            )

    @property
    def is_bottleneck(self) -> bool:
        """Check if operation is a bottleneck (>20% of total time)."""
        return self.bottleneck_score > 0.2

    @property
    def is_critical_bottleneck(self) -> bool:
        """Check if operation is a critical bottleneck (>50% of total time)."""
        return self.bottleneck_score > 0.5


@dataclass
class OptimizationRecommendation:
    """
    Specific optimization recommendation with expected impact.

    Generated by performance analysis to guide optimization efforts.

    Attributes:
        area: Optimization area (template_cache, parallel_execution, etc.)
        issue: Description of the performance issue
        recommendation: Specific action to take
        expected_improvement: Expected performance gain (e.g., "10-20% faster")
        priority: Priority level based on impact
        current_value: Current performance metric value
        target_value: Target performance metric value
        implementation_notes: Additional implementation guidance
        related_operations: Operations affected by this optimization
    """

    area: OptimizationArea
    issue: str
    recommendation: str
    expected_improvement: str
    priority: OptimizationPriority
    current_value: Optional[float] = None
    target_value: Optional[float] = None
    implementation_notes: str = ""
    related_operations: list[str] = field(default_factory=list)

    @property
    def impact_description(self) -> str:
        """Get human-readable impact description."""
        if self.priority == OptimizationPriority.CRITICAL:
            return "Critical impact (>50% improvement)"
        elif self.priority == OptimizationPriority.HIGH:
            return "High impact (20-50% improvement)"
        elif self.priority == OptimizationPriority.MEDIUM:
            return "Medium impact (10-20% improvement)"
        else:
            return "Low impact (<10% improvement)"


class TemplateCacheStats(BaseModel):
    """
    Template cache performance statistics.

    Tracks cache efficiency and provides optimization guidance.
    """

    total_requests: int = Field(
        default=0, description="Total number of template requests"
    )
    cache_hits: int = Field(default=0, description="Number of cache hits")
    cache_misses: int = Field(default=0, description="Number of cache misses")
    hit_rate: float = Field(
        default=0.0, ge=0.0, le=1.0, description="Cache hit rate (0-1)"
    )
    avg_hit_time_ms: float = Field(
        default=0.0, ge=0.0, description="Average time for cache hit (ms)"
    )
    avg_miss_time_ms: float = Field(
        default=0.0, ge=0.0, description="Average time for cache miss (ms)"
    )
    cache_size: int = Field(default=0, ge=0, description="Current cache size")
    max_cache_size: int = Field(default=100, ge=1, description="Maximum cache size")
    eviction_count: int = Field(
        default=0, ge=0, description="Number of cache evictions"
    )
    preloaded_templates: int = Field(
        default=0, ge=0, description="Number of preloaded templates"
    )

    @property
    def needs_optimization(self) -> bool:
        """Check if cache needs optimization (hit rate < 95%)."""
        return self.hit_rate < 0.95

    @property
    def is_full(self) -> bool:
        """Check if cache is at capacity."""
        return self.cache_size >= self.max_cache_size

    def get_optimization_recommendation(self) -> Optional[OptimizationRecommendation]:
        """Generate optimization recommendation if needed."""
        if not self.needs_optimization:
            return None

        if self.hit_rate < 0.85:
            priority = OptimizationPriority.CRITICAL
            expected = "30-50% faster template operations"
        elif self.hit_rate < 0.90:
            priority = OptimizationPriority.HIGH
            expected = "20-30% faster template operations"
        else:
            priority = OptimizationPriority.MEDIUM
            expected = "10-20% faster template operations"

        return OptimizationRecommendation(
            area=OptimizationArea.TEMPLATE_CACHE,
            issue=f"Template cache hit rate is {self.hit_rate:.1%} (target: 95%)",
            recommendation="Preload frequently used templates and increase cache size",
            expected_improvement=expected,
            priority=priority,
            current_value=self.hit_rate,
            target_value=0.95,
            implementation_notes=(
                "Analyze template access patterns and preload top 20 templates. "
                f"Consider increasing cache size from {self.max_cache_size} to "
                f"{int(self.max_cache_size * 1.5)} if eviction_count is high "
                f"({self.eviction_count} evictions)."
            ),
        )


class ParallelExecutionStats(BaseModel):
    """
    Parallel execution performance statistics.

    Tracks parallelization efficiency and concurrency optimization.
    """

    total_operations: int = Field(default=0, description="Total number of operations")
    parallel_operations: int = Field(
        default=0, description="Operations executed in parallel"
    )
    sequential_time_ms: float = Field(
        default=0.0, ge=0.0, description="Time if executed sequentially (ms)"
    )
    parallel_time_ms: float = Field(
        default=0.0, ge=0.0, description="Actual parallel execution time (ms)"
    )
    speedup_factor: float = Field(
        default=1.0, ge=1.0, description="Speedup factor (sequential/parallel)"
    )
    max_concurrent_tasks: int = Field(
        default=10, ge=1, description="Maximum concurrent tasks allowed"
    )
    avg_concurrent_tasks: float = Field(
        default=1.0, ge=1.0, description="Average concurrent tasks"
    )
    cpu_utilization: float = Field(
        default=0.0, ge=0.0, le=1.0, description="CPU utilization (0-1)"
    )
    coordination_overhead_ms: float = Field(
        default=0.0, ge=0.0, description="Coordination overhead (ms)"
    )

    @property
    def needs_optimization(self) -> bool:
        """Check if parallel execution needs optimization (speedup < 3x)."""
        return self.speedup_factor < 3.0 and self.parallel_operations > 1

    @property
    def has_low_utilization(self) -> bool:
        """Check if CPU utilization is low (<70%)."""
        return self.cpu_utilization < 0.7

    def get_optimization_recommendation(self) -> Optional[OptimizationRecommendation]:
        """Generate optimization recommendation if needed."""
        if not self.needs_optimization:
            return None

        if self.speedup_factor < 2.0:
            priority = OptimizationPriority.CRITICAL
            expected = "50-100% faster parallel execution"
        elif self.speedup_factor < 2.5:
            priority = OptimizationPriority.HIGH
            expected = "30-50% faster parallel execution"
        else:
            priority = OptimizationPriority.MEDIUM
            expected = "15-30% faster parallel execution"

        # Determine specific issue and recommendation
        if self.has_low_utilization:
            issue = (
                f"Low CPU utilization ({self.cpu_utilization:.1%}) "
                f"with speedup {self.speedup_factor:.2f}x (target: 3-4x)"
            )
            recommendation = (
                f"Increase max_concurrent_tasks from {self.max_concurrent_tasks} to "
                f"{int(self.max_concurrent_tasks * 1.5)} and reduce coordination overhead"
            )
        else:
            issue = (
                f"Speedup is {self.speedup_factor:.2f}x (target: 3-4x) "
                f"with high coordination overhead ({self.coordination_overhead_ms:.1f}ms)"
            )
            recommendation = (
                "Optimize coordination overhead by batching operations "
                "and reducing synchronization points"
            )

        return OptimizationRecommendation(
            area=OptimizationArea.PARALLEL_EXECUTION,
            issue=issue,
            recommendation=recommendation,
            expected_improvement=expected,
            priority=priority,
            current_value=self.speedup_factor,
            target_value=3.5,
            implementation_notes=(
                "Analyze task dependencies to maximize parallelism. "
                "Consider adjusting batch sizes and reducing inter-task communication."
            ),
        )


class MemoryUsageStats(BaseModel):
    """
    Memory usage statistics for performance optimization.

    Tracks memory consumption and identifies optimization opportunities.
    """

    peak_memory_mb: float = Field(
        default=0.0, ge=0.0, description="Peak memory usage (MB)"
    )
    avg_memory_mb: float = Field(
        default=0.0, ge=0.0, description="Average memory usage (MB)"
    )
    memory_allocations: int = Field(
        default=0, ge=0, description="Number of memory allocations"
    )
    memory_deallocations: int = Field(
        default=0, ge=0, description="Number of memory deallocations"
    )
    gc_collections: int = Field(
        default=0, ge=0, description="Number of garbage collections"
    )
    large_allocations: int = Field(
        default=0, ge=0, description="Number of large allocations (>10MB)"
    )
    memory_overhead_mb: float = Field(
        default=0.0, ge=0.0, description="Memory overhead vs baseline (MB)"
    )

    @property
    def needs_optimization(self) -> bool:
        """Check if memory usage needs optimization (overhead > 50MB)."""
        return self.memory_overhead_mb > 50.0

    @property
    def has_excessive_gc(self) -> bool:
        """Check if GC collections are excessive (>100)."""
        return self.gc_collections > 100

    def get_optimization_recommendation(self) -> Optional[OptimizationRecommendation]:
        """Generate optimization recommendation if needed."""
        if not self.needs_optimization:
            return None

        if self.memory_overhead_mb > 100.0:
            priority = OptimizationPriority.CRITICAL
            expected = "50-70% memory reduction"
        elif self.memory_overhead_mb > 75.0:
            priority = OptimizationPriority.HIGH
            expected = "30-50% memory reduction"
        else:
            priority = OptimizationPriority.MEDIUM
            expected = "15-30% memory reduction"

        return OptimizationRecommendation(
            area=OptimizationArea.MEMORY,
            issue=(
                f"Memory overhead is {self.memory_overhead_mb:.1f}MB (target: <50MB) "
                f"with {self.large_allocations} large allocations"
            ),
            recommendation=(
                "Enable streaming for large files, use object pooling, "
                "and reduce unnecessary data copies"
            ),
            expected_improvement=expected,
            priority=priority,
            current_value=self.memory_overhead_mb,
            target_value=50.0,
            implementation_notes=(
                f"Peak memory: {self.peak_memory_mb:.1f}MB, "
                f"GC collections: {self.gc_collections}. "
                "Consider using generators instead of lists for large datasets "
                "and implementing object pooling for frequently created objects."
            ),
        )


class IOPerformanceStats(BaseModel):
    """
    I/O performance statistics for optimization.

    Tracks file system and network I/O efficiency.
    """

    total_io_operations: int = Field(
        default=0, ge=0, description="Total I/O operations"
    )
    sync_io_operations: int = Field(
        default=0, ge=0, description="Synchronous I/O operations"
    )
    async_io_operations: int = Field(
        default=0, ge=0, description="Asynchronous I/O operations"
    )
    total_io_time_ms: float = Field(
        default=0.0, ge=0.0, description="Total I/O time (ms)"
    )
    avg_io_time_ms: float = Field(
        default=0.0, ge=0.0, description="Average I/O time per operation (ms)"
    )
    batched_operations: int = Field(
        default=0, ge=0, description="Number of batched I/O operations"
    )
    io_wait_time_ms: float = Field(
        default=0.0, ge=0.0, description="Time spent waiting for I/O (ms)"
    )

    @property
    def needs_optimization(self) -> bool:
        """Check if I/O needs optimization (>50% sync operations)."""
        if self.total_io_operations == 0:
            return False
        sync_ratio = self.sync_io_operations / self.total_io_operations
        return sync_ratio > 0.5 or self.avg_io_time_ms > 10.0

    @property
    def async_ratio(self) -> float:
        """Calculate ratio of async I/O operations."""
        if self.total_io_operations == 0:
            return 0.0
        return self.async_io_operations / self.total_io_operations

    def get_optimization_recommendation(self) -> Optional[OptimizationRecommendation]:
        """Generate optimization recommendation if needed."""
        if not self.needs_optimization:
            return None

        sync_ratio = (
            self.sync_io_operations / self.total_io_operations
            if self.total_io_operations > 0
            else 0.0
        )

        if sync_ratio > 0.7:
            priority = OptimizationPriority.CRITICAL
            expected = "50-70% faster I/O operations"
        elif sync_ratio > 0.6:
            priority = OptimizationPriority.HIGH
            expected = "30-50% faster I/O operations"
        else:
            priority = OptimizationPriority.MEDIUM
            expected = "15-30% faster I/O operations"

        return OptimizationRecommendation(
            area=OptimizationArea.IO,
            issue=(
                f"Sync I/O ratio is {sync_ratio:.1%} (target: <50%) "
                f"with avg I/O time {self.avg_io_time_ms:.1f}ms"
            ),
            recommendation=(
                "Convert synchronous I/O to async I/O and implement operation batching"
            ),
            expected_improvement=expected,
            priority=priority,
            current_value=sync_ratio,
            target_value=0.5,
            implementation_notes=(
                f"Convert {self.sync_io_operations} sync operations to async. "
                f"Current batching: {self.batched_operations} operations. "
                "Consider using aiofiles for file I/O and batching small operations."
            ),
        )


@dataclass
class PerformanceReport:
    """
    Comprehensive performance analysis report.

    Combines profiling results with optimization recommendations.

    Attributes:
        workflow_id: Workflow identifier
        total_duration_ms: Total workflow duration
        profile_results: Detailed profiling results per operation
        hot_paths: Top bottleneck operations
        recommendations: Prioritized optimization recommendations
        template_cache_stats: Template cache statistics
        parallel_execution_stats: Parallel execution statistics
        memory_stats: Memory usage statistics
        io_stats: I/O performance statistics
        timestamp: When report was generated
        metadata: Additional report metadata
    """

    workflow_id: str
    total_duration_ms: float
    profile_results: dict[str, ProfileResult]
    hot_paths: list[ProfileResult]
    recommendations: list[OptimizationRecommendation]
    template_cache_stats: Optional[TemplateCacheStats] = None
    parallel_execution_stats: Optional[ParallelExecutionStats] = None
    memory_stats: Optional[MemoryUsageStats] = None
    io_stats: Optional[IOPerformanceStats] = None
    timestamp: datetime = field(default_factory=datetime.utcnow)
    metadata: dict[str, Any] = field(default_factory=dict)

    @property
    def critical_recommendations(self) -> list[OptimizationRecommendation]:
        """Get critical priority recommendations."""
        return [
            rec
            for rec in self.recommendations
            if rec.priority == OptimizationPriority.CRITICAL
        ]

    @property
    def high_recommendations(self) -> list[OptimizationRecommendation]:
        """Get high priority recommendations."""
        return [
            rec
            for rec in self.recommendations
            if rec.priority == OptimizationPriority.HIGH
        ]

    @property
    def estimated_speedup(self) -> float:
        """
        Estimate potential speedup from recommendations.

        Returns estimated speedup factor (e.g., 2.5x).
        """
        # Conservative estimate: sum critical (50%) + high (30%) improvements
        speedup = 1.0
        for rec in self.critical_recommendations:
            speedup += 0.5  # 50% improvement per critical issue
        for rec in self.high_recommendations:
            speedup += 0.3  # 30% improvement per high priority issue
        return min(speedup, 5.0)  # Cap at 5x for realism

    def get_summary(self) -> str:
        """Get human-readable performance report summary."""
        lines = [
            f"Performance Report: {self.workflow_id}",
            f"Total Duration: {self.total_duration_ms:.2f}ms",
            f"Profiled Operations: {len(self.profile_results)}",
            f"Hot Paths (Bottlenecks): {len(self.hot_paths)}",
            f"Recommendations: {len(self.recommendations)} "
            f"({len(self.critical_recommendations)} critical, "
            f"{len(self.high_recommendations)} high priority)",
            f"Estimated Speedup: {self.estimated_speedup:.2f}x",
        ]

        if self.template_cache_stats:
            lines.append(
                f"Template Cache Hit Rate: {self.template_cache_stats.hit_rate:.1%}"
            )

        if self.parallel_execution_stats:
            lines.append(
                f"Parallel Speedup: {self.parallel_execution_stats.speedup_factor:.2f}x"
            )

        if self.memory_stats:
            lines.append(
                f"Memory Overhead: {self.memory_stats.memory_overhead_mb:.1f}MB"
            )

        return "\n".join(lines)


@dataclass
class DryRunChange:
    """
    Record of a proposed optimization change in dry-run mode.

    Tracks what would be changed without actually applying modifications.

    Attributes:
        area: Optimization area being modified
        change_type: Type of change (e.g., "config_update", "preload", "tuning")
        description: Human-readable description of the change
        current_value: Current value before change
        proposed_value: Proposed value after change
        expected_impact: Expected performance impact
        affected_components: List of components that would be affected
        recommendation: Associated optimization recommendation
    """

    area: OptimizationArea
    change_type: str
    description: str
    current_value: Union[str, float, int, bool, None] = None
    proposed_value: Union[str, float, int, bool, None] = None
    expected_impact: str = ""
    affected_components: list[str] = field(default_factory=list)
    recommendation: Optional[OptimizationRecommendation] = None

    def get_summary(self) -> str:
        """Get human-readable change summary."""
        lines = [
            f"[{self.area.value.upper()}] {self.change_type}: {self.description}",
        ]

        if self.current_value is not None and self.proposed_value is not None:
            lines.append(f"  Current: {self.current_value}")
            lines.append(f"  Proposed: {self.proposed_value}")

        if self.expected_impact:
            lines.append(f"  Impact: {self.expected_impact}")

        if self.affected_components:
            components = ", ".join(self.affected_components)
            lines.append(f"  Affects: {components}")

        return "\n".join(lines)


@dataclass
class DryRunReport:
    """
    Comprehensive report of proposed optimizations in dry-run mode.

    Provides detailed analysis of what would be changed without actually
    applying modifications to the system.

    Attributes:
        workflow_id: Workflow identifier
        total_changes: Total number of proposed changes
        changes: List of proposed changes
        critical_changes: Changes from critical recommendations
        high_priority_changes: Changes from high priority recommendations
        estimated_speedup: Estimated speedup if all changes applied
        timestamp: When dry-run was performed
        metadata: Additional dry-run metadata
    """

    workflow_id: str
    total_changes: int
    changes: list[DryRunChange]
    critical_changes: list[DryRunChange]
    high_priority_changes: list[DryRunChange]
    estimated_speedup: float
    timestamp: datetime = field(default_factory=datetime.utcnow)
    metadata: dict[str, Any] = field(default_factory=dict)

    @property
    def changes_by_area(self) -> dict[str, list[DryRunChange]]:
        """Group changes by optimization area."""
        result: dict[str, list[DryRunChange]] = {}
        for change in self.changes:
            area = change.area.value
            if area not in result:
                result[area] = []
            result[area].append(change)
        return result

    @property
    def affected_components(self) -> set[str]:
        """Get all affected components across all changes."""
        components = set()
        for change in self.changes:
            components.update(change.affected_components)
        return components

    def get_summary(self) -> str:
        """Get human-readable dry-run summary."""
        lines = [
            "=" * 60,
            f"DRY-RUN REPORT: {self.workflow_id}",
            "=" * 60,
            f"Total Proposed Changes: {self.total_changes}",
            f"  - Critical: {len(self.critical_changes)}",
            f"  - High Priority: {len(self.high_priority_changes)}",
            f"Estimated Speedup: {self.estimated_speedup:.2f}x",
            f"Affected Components: {len(self.affected_components)}",
            "",
            "PROPOSED CHANGES:",
            "-" * 60,
        ]

        # Group changes by area
        for area, area_changes in self.changes_by_area.items():
            lines.append(f"\n{area.upper()} ({len(area_changes)} changes):")
            for change in area_changes:
                lines.append(f"\n{change.get_summary()}")

        lines.extend(
            [
                "",
                "-" * 60,
                "NOTE: This is a DRY-RUN. No changes have been applied.",
                "To apply these optimizations, run with dry_run=False.",
                "=" * 60,
            ]
        )

        return "\n".join(lines)

    def export_json(self) -> dict[str, Any]:
        """Export dry-run report as JSON-serializable dictionary."""
        return {
            "workflow_id": self.workflow_id,
            "total_changes": self.total_changes,
            "estimated_speedup": self.estimated_speedup,
            "timestamp": self.timestamp.isoformat(),
            "changes": [
                {
                    "area": change.area.value,
                    "change_type": change.change_type,
                    "description": change.description,
                    "current_value": change.current_value,
                    "proposed_value": change.proposed_value,
                    "expected_impact": change.expected_impact,
                    "affected_components": change.affected_components,
                }
                for change in self.changes
            ],
            "changes_by_area": {
                area: len(changes) for area, changes in self.changes_by_area.items()
            },
            "affected_components": sorted(self.affected_components),
            "metadata": self.metadata,
        }
