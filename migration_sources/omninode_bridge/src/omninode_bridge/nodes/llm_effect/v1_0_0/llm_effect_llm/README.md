# NodeLlmEffectEffect

## Overview

LLM Effect Node for multi-tier LLM generation with Z.ai integration. Supports CLOUD_FAST (GLM-4.5) tier with 128K context window. Includes circuit breaker, retry logic, token tracking, and cost management.

**Node Type**: effect
**Domain**: ai_services
**Generated**: 2025-11-05T13:31:05.422648+00:00

## Operations

- `generate_text`
- `calculate_cost`
- `track_usage`

## Features

- Multi-tier LLM support (LOCAL, CLOUD_FAST, CLOUD_PREMIUM)
- Z.ai API integration (Anthropic-compatible endpoint)
- GLM-4.5 model support (PRIMARY tier)
- Circuit breaker pattern for fault tolerance
- Retry logic with exponential backoff
- HTTP client with connection pooling
- Token usage tracking (input/output/total)
- Cost tracking with sub-cent accuracy
- Comprehensive metrics collection via MixinMetrics
- Performance monitoring (latency, throughput)
- Health checks via MixinHealthCheck
- Z.ai API health monitoring
- Structured logging with correlation tracking
- OpenTelemetry tracing support
- Environment-based credentials (ZAI_API_KEY)
- Configurable timeouts and thresholds
- Per-tier pricing configuration

## Performance Requirements

- latency_p95_ms: 3000
- throughput_rps: 10
- max_memory_mb: 512
- max_cpu_percent: 25

## Usage

```python
from omninode_bridge.nodes.llm_effect.v1_0_0 import NodeLlmEffectEffect
from omnibase_core.models.core import ModelContainer
from omnibase_core.models.contracts.model_contract_effect import ModelContractEffect
from omnibase_core.enums.enum_node_type import EnumNodeType
from uuid import uuid4

# Initialize container with configuration
container = ModelContainer(
    value={"environment": "production", "log_level": "INFO"},
    container_type="config"
)
node = NodeLlmEffectEffect(container)

# Create contract with complete configuration
contract = ModelContractEffect(
    name="generate_text",
    version={"major": 1, "minor": 0, "patch": 0},
    description="Execute generate_text",
    node_type=EnumNodeType.EFFECT,
    input_model="ModelNodeLlmEffectEffectInput",
    output_model="ModelNodeLlmEffectEffectOutput",
    correlation_id=uuid4(),
    execution_id=uuid4()
)

# Execute the operation
result = await node.execute_effect(contract)
print(f"Result: {result}")
```

## Testing

```bash
pytest tests/test_node.py -v
```

## ONEX v2.0 Compliance

✅ Suffix-based naming: `NodeLlmEffectEffect`
✅ Contract-driven architecture
✅ Event-driven patterns
✅ Comprehensive error handling
✅ Performance monitoring

---

Generated by OmniNode Code Generation Pipeline
