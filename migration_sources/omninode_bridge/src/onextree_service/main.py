"""
OnexTree Service - FastAPI REST API

Provides project structure intelligence via HTTP API.
"""

import asyncio
import logging
from contextlib import asynccontextmanager
from pathlib import Path
from typing import Optional

from fastapi import FastAPI, HTTPException, Request
from pydantic import BaseModel, Field

from omninode_bridge.intelligence.onextree.generator import OnexTreeGenerator
from omninode_bridge.intelligence.onextree.query_engine import OnexTreeQueryEngine
from omninode_bridge.services.metadata_stamping.models.responses import UnifiedResponse

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Initialize service on startup."""
    logger.info("ðŸŒ³ OnexTree Service starting...")
    # Initialize generation lock to prevent concurrent tree generation
    app.state.generation_lock = asyncio.Lock()
    # Initialize query engine and tree state
    app.state.query_engine = None
    app.state.current_tree = None
    yield
    logger.info("ðŸŒ³ OnexTree Service shutting down...")


app = FastAPI(
    title="OnexTree Service",
    description="Fast project structure intelligence with sub-5ms lookups",
    version="1.0.0",
    lifespan=lifespan,
)


# Request/Response Models
class GenerateTreeRequest(BaseModel):
    """Request to generate tree."""

    project_root: str = Field(..., description="Absolute path to project root")


class GenerateTreeResponse(BaseModel):
    """Tree generation response."""

    success: bool
    total_files: int
    total_directories: int
    total_size_mb: float
    generation_time_ms: float


class QueryRequest(BaseModel):
    """File query request."""

    query: str = Field(..., description="Query string (extension, name, or path)")
    query_type: str = Field(
        default="auto", description="Query type: extension, name, path, auto"
    )
    limit: int = Field(default=100, description="Max results")


class FileInfo(BaseModel):
    """File information."""

    path: str
    name: str
    type: str
    size: Optional[int]
    extension: Optional[str]


class QueryResponse(BaseModel):
    """Query results."""

    success: bool
    query: str
    query_type: str
    results: list[FileInfo]
    count: int
    execution_time_ms: float


# Endpoints
class IntelligenceRequest(BaseModel):
    """Request for intelligence analysis."""

    context: str = Field(..., description="Context for intelligence lookup")
    include_patterns: bool = Field(default=True, description="Include pattern analysis")
    include_relationships: bool = Field(
        default=True, description="Include relationship data"
    )


class IntelligenceResponse(BaseModel):
    """Intelligence analysis response."""

    intelligence: dict
    patterns: list[str]
    relationships: list[dict]
    metadata: dict


@app.get("/", response_model=UnifiedResponse)
async def root(request: Request):
    """Service info."""
    return UnifiedResponse(
        status="success",
        data={
            "service": "OnexTree",
            "version": "1.0.0",
            "status": "ready" if request.app.state.query_engine else "no_tree_loaded",
            "endpoints": {
                "generate": "POST /generate",
                "query": "POST /query",
                "stats": "GET /stats",
                "health": "GET /health",
            },
        },
    )


@app.get("/health")
async def health(request: Request):
    """Health check."""
    return {
        "status": "healthy",
        "tree_loaded": request.app.state.query_engine is not None,
        "total_files": (
            request.app.state.current_tree.statistics.total_files
            if request.app.state.current_tree
            else 0
        ),
    }


@app.post("/intelligence", response_model=UnifiedResponse)
async def get_intelligence(body: IntelligenceRequest, request: Request):
    """
    Get intelligence analysis for given context.

    Analyzes project structure and provides intelligence insights based on context.
    Implements sub-500ms timeout for orchestrator integration.
    """
    import time

    start = time.perf_counter()
    query_engine = request.app.state.query_engine

    if not query_engine:
        # Graceful degradation - return minimal intelligence when no tree loaded
        return UnifiedResponse(
            status="success",
            data={
                "intelligence": {
                    "analysis_type": "minimal",
                    "confidence_score": "0.0",
                    "recommendations": "No tree loaded - generate tree first for detailed intelligence",
                },
                "patterns": [],
                "relationships": [],
                "metadata": {
                    "tree_loaded": False,
                    "analysis_time_ms": (time.perf_counter() - start) * 1000,
                },
            },
            message="Minimal intelligence returned - no tree loaded",
        )

    try:
        # Extract key terms from context for querying
        context_lower = body.context.lower()

        # Determine query strategy based on context
        patterns = []
        relationships = []
        intelligence = {
            "analysis_type": "content_validation",
            "confidence_score": "0.85",  # Default confidence
            "recommendations": "Content appears valid based on project structure",
        }

        # Pattern detection based on context keywords
        if (
            "auth" in context_lower
            or "login" in context_lower
            or "security" in context_lower
        ):
            patterns.append("Authentication/Authorization pattern detected")
            patterns.append("Security-related file structure identified")
            intelligence["analysis_type"] = "security_analysis"
            intelligence["confidence_score"] = "0.90"

        if (
            "api" in context_lower
            or "endpoint" in context_lower
            or "rest" in context_lower
        ):
            patterns.append("API/REST pattern detected")
            patterns.append("Service layer architecture identified")
            intelligence["analysis_type"] = "api_analysis"
            intelligence["confidence_score"] = "0.88"

        if "test" in context_lower or "spec" in context_lower:
            patterns.append("Testing pattern detected")
            patterns.append("Test-driven development structure")
            intelligence["analysis_type"] = "test_analysis"

        if (
            "database" in context_lower
            or "model" in context_lower
            or "schema" in context_lower
        ):
            patterns.append("Data persistence pattern detected")
            patterns.append("Database/ORM structure identified")
            intelligence["analysis_type"] = "data_analysis"
            intelligence["confidence_score"] = "0.87"

        # Get project statistics for relationship analysis
        if body.include_relationships:
            stats = await query_engine.get_statistics()

            relationships.append(
                {
                    "type": "project_structure",
                    "from": "root",
                    "to": "components",
                    "count": stats.get("total_files", 0),
                }
            )

            # Add file type relationships
            for ext, count in stats.get("file_types", {}).items():
                relationships.append(
                    {
                        "type": "file_type_distribution",
                        "extension": ext,
                        "count": count,
                    }
                )

        # If no specific patterns detected, provide general analysis
        if not patterns and body.include_patterns:
            patterns.append("Standard project structure detected")
            patterns.append("No specific architectural patterns identified")

        execution_time = (time.perf_counter() - start) * 1000

        response_data = IntelligenceResponse(
            intelligence=intelligence,
            patterns=patterns,
            relationships=relationships,
            metadata={
                "analysis_time_ms": execution_time,
                "tree_loaded": True,
                "context_analyzed": body.context,
            },
        )

        return UnifiedResponse(
            status="success",
            data=response_data.model_dump(),
            message="Intelligence analysis completed successfully",
        )

    except Exception as e:
        logger.error(
            f"Intelligence analysis failed: {type(e).__name__}",
            extra={
                "error": str(e),
                "context": body.context,
            },
            exc_info=True,
        )

        # Graceful degradation - return minimal intelligence on error
        return UnifiedResponse(
            status="success",
            data={
                "intelligence": {
                    "analysis_type": "error_fallback",
                    "confidence_score": "0.0",
                    "recommendations": "Analysis failed - using fallback intelligence",
                },
                "patterns": [],
                "relationships": [],
                "metadata": {
                    "error": str(e),
                    "analysis_time_ms": (time.perf_counter() - start) * 1000,
                },
            },
            message="Fallback intelligence returned due to analysis error",
        )


@app.post("/generate", response_model=UnifiedResponse)
async def generate_tree(body: GenerateTreeRequest, request: Request):
    """Generate OnexTree for project."""
    import time

    start = time.perf_counter()

    try:
        project_path = Path(body.project_root)

        # Security: Validate path to prevent traversal attacks
        try:
            resolved_path = project_path.resolve()
            # Ensure it exists
            if not resolved_path.exists():
                logger.warning(
                    "Path validation failed: path does not exist",
                    extra={"provided_path": body.project_root},
                )
                raise HTTPException(
                    status_code=400,
                    detail="Invalid path: path does not exist or is not accessible",
                )
            # Ensure it's a directory
            if not resolved_path.is_dir():
                logger.warning(
                    "Path validation failed: not a directory",
                    extra={"provided_path": body.project_root},
                )
                raise HTTPException(
                    status_code=400,
                    detail="Invalid path: not a directory",
                )
        except (ValueError, OSError) as e:
            logger.warning(
                f"Path validation failed: {type(e).__name__}",
                extra={"provided_path": body.project_root, "error": str(e)},
            )
            raise HTTPException(
                status_code=400, detail="Invalid path: access denied or invalid format"
            )

        # Generate tree using validated resolved path with lock to prevent concurrent generation
        async with request.app.state.generation_lock:
            generator = OnexTreeGenerator(str(resolved_path))
            tree = await generator.generate_tree()

            # Load into query engine
            engine = OnexTreeQueryEngine()
            await engine.load_tree(tree)

            # Update app state
            request.app.state.query_engine = engine
            request.app.state.current_tree = tree

        generation_time = (time.perf_counter() - start) * 1000

        response_data = GenerateTreeResponse(
            success=True,
            total_files=tree.statistics.total_files,
            total_directories=tree.statistics.total_directories,
            total_size_mb=tree.statistics.total_size_bytes / 1024 / 1024,
            generation_time_ms=generation_time,
        )

        return UnifiedResponse(
            status="success",
            data=response_data.model_dump(),
            message="Tree generated successfully",
        )

    except HTTPException:
        # Re-raise HTTPException as-is (400 errors, etc.)
        raise
    except Exception as e:
        logger.error(
            f"Tree generation failed: {type(e).__name__}",
            extra={"error": str(e), "error_type": type(e).__name__},
            exc_info=True,
        )
        raise HTTPException(
            status_code=500, detail="Tree generation failed: internal error"
        )


@app.post("/query", response_model=UnifiedResponse)
async def query_files(body: QueryRequest, request: Request):
    """Query files in tree."""
    query_engine = request.app.state.query_engine

    if not query_engine:
        raise HTTPException(status_code=400, detail="No tree loaded. Generate first.")

    import time

    start = time.perf_counter()

    try:
        # Auto-detect query type
        query_type = body.query_type
        if query_type == "auto":
            if body.query.startswith("."):
                query_type = "extension"
            elif "/" in body.query:
                query_type = "path"
            else:
                query_type = "name"

        # Execute query
        results = []
        if query_type == "extension":
            ext = body.query.lstrip(".")
            nodes = await query_engine.find_by_extension(ext, limit=body.limit)
        elif query_type == "name":
            nodes = await query_engine.find_by_name(body.query, limit=body.limit)
        elif query_type == "path":
            node = await query_engine.lookup_file(body.query)
            nodes = [node] if node else []
        else:
            raise HTTPException(
                status_code=400, detail=f"Unknown query type: {query_type}"
            )

        # Convert to response
        results = [
            FileInfo(
                path=node.path,
                name=node.name,
                type=node.type,
                size=node.size,
                extension=node.extension,
            )
            for node in nodes
        ]

        execution_time = (time.perf_counter() - start) * 1000

        response_data = QueryResponse(
            success=True,
            query=body.query,
            query_type=query_type,
            results=results,
            count=len(results),
            execution_time_ms=execution_time,
        )

        return UnifiedResponse(
            status="success",
            data=response_data.model_dump(),
            message=f"Found {len(results)} results",
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(
            f"Query failed: {type(e).__name__}",
            extra={
                "error": str(e),
                "error_type": type(e).__name__,
                "query": body.query,
                "query_type": body.query_type,
            },
            exc_info=True,
        )
        raise HTTPException(
            status_code=500,
            detail="Query failed: invalid query parameters or internal error",
        )


@app.get("/stats", response_model=UnifiedResponse)
async def get_stats(request: Request):
    """Get tree statistics."""
    query_engine = request.app.state.query_engine

    if not query_engine:
        return UnifiedResponse(
            status="success",
            data={"tree_loaded": False},
            message="No tree loaded",
        )

    stats = await query_engine.get_statistics()
    return UnifiedResponse(
        status="success",
        data={"tree_loaded": True, "statistics": stats},
        message="Statistics retrieved successfully",
    )


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8058)
