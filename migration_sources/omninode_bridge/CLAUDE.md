# OmniNode Bridge - Implementation Guide

> **üìö Shared Infrastructure**: For common OmniNode infrastructure (PostgreSQL, Kafka/Redpanda, remote server topology, Docker networking, environment variables), see **`~/.claude/CLAUDE.md`**. This file contains OmniNode Bridge-specific architecture, nodes, and deployment only.

## Project Overview

**‚ö†Ô∏è MVP FOUNDATION NOTICE**

This repository contains the **MVP foundation** for the omninode ecosystem, providing core bridge nodes, event infrastructure, and integration patterns. This is a **working MVP** that will eventually be split into separate repositories as functionality matures.

**Purpose:** MVP implementation of bridge nodes connecting omninode services, with production-grade event infrastructure, database persistence, and workflow orchestration. This repository serves as the unified foundation before splitting into specialized repos.

**Current Status:** Phase 1 & 2 Complete - Production-ready MVP with event infrastructure, database persistence, Kafka publishing, and bridge nodes fully integrated.

**Future Evolution:** As the MVP matures, functionality will be extracted into dedicated repositories (event infrastructure ‚Üí omninode-events, bridge nodes ‚Üí omninode-bridge-nodes, etc.).

### Recent Completions (October 2025)

**Event Infrastructure:**
- 13 Kafka topics with OnexEnvelopeV1 format
- Database-backed event tracing and metrics
- DLQ monitoring with threshold-based alerting

**Bridge Node Integration:**
- PostgreSQL persistence for workflow and bridge states
- Kafka event publishing at all lifecycle stages
- 92.8% test coverage with 501 tests

**Repository Strategy:**
- Closed 6 stale PRs (speculative features)
- Preserved valuable patterns in docs/patterns/
- Clarified MVP foundation approach with future repo split plan

### Key Enhancements

- **O.N.E. v0.1 Protocol Compliance**: Full compliance with One.Node.Enterprise v0.1 standards
- **Namespace Support**: Multi-tenant organization with `omninode.services.metadata` namespace
- **Unified Response Format**: Consistent API responses with enhanced error handling
- **Kafka Event Publishing**: Real-time event streaming with OnexEnvelopeV1 format
- **Enhanced Schema**: Intelligence data, operation tracking, and compliance fields
- **Batch Operations**: Multi-stamp processing capabilities (API endpoints planned)
- **Protocol Validation**: O.N.E. v0.1 compliance validation (API endpoints planned)

## Core Components

1. **FastAPI Service** - Async architecture with PostgreSQL integration and unified response format
2. **BLAKE3HashGenerator** - Sub-2ms hash generation with batch processing and enhanced metrics
3. **ProtocolFileTypeHandler** - O.N.E. v0.1 protocol compliance and file type detection
4. **Database Layer** - Connection pooling, prepared statements, O.N.E. v0.1 schema compliance
5. **Event Publisher** - Kafka event streaming with OnexEnvelopeV1 format
6. **Namespace Manager** - Multi-tenant organization and isolation
7. **Monitoring System** - Enhanced metrics collection with partitioned storage

## Performance Requirements

- BLAKE3 hashing: < 2ms per operation
- API response: < 10ms for standard operations
- Throughput: 1000+ concurrent requests
- Memory: < 512MB under normal load
- Database: 20-50 connection pool

## Database Schema

**O.N.E. v0.1 Compliant PostgreSQL Schema**

**Tables:**
- `metadata_stamps` - Metadata stamps with O.N.E. v0.1 compliance fields
- `protocol_handlers` - Protocol handlers with enhanced configuration
- `hash_metrics` - Partitioned metrics for performance monitoring

**Key Performance Optimizations:**
- Connection pooling (10-50 connections)
- GIN indexes on JSONB fields for fast intelligence queries
- Partitioned hash_metrics table for time-series data
- Circuit breaker pattern for resilience

**Schema Details:** See [migrations/schema.sql](./migrations/schema.sql)

## BLAKE3HashGenerator Implementation

### Key Features

- **Pool Management**: Pre-allocated hasher pool (100 instances)
- **Buffer Optimization**: Adaptive sizing (8KB-1MB) based on file size
- **Thread Pool**: CPU-intensive operations in dedicated threads
- **Performance Monitoring**: Real-time metrics collection
- **Batch Processing**: Concurrent hash generation with semaphore control

### Optimization Techniques

- **Memory Pool**: Zero-allocation hot path with pre-allocated hashers
- **Buffer Sizing**: 8KB (small), 64KB (medium), 1MB (large) files
- **Thread Execution**: Non-blocking CPU-intensive operations
- **Weak References**: Automatic cleanup of cached objects
- **Batch Semaphore**: Controlled concurrency (10 concurrent operations)

## ProtocolFileTypeHandler

### Supported File Types

- **Images**: .jpg, .jpeg, .png, .gif, .bmp, .webp
- **Documents**: .pdf, .doc, .docx, .txt, .md
- **Audio**: .mp3, .wav, .flac, .aac, .ogg
- **Video**: .mp4, .avi, .mkv, .mov, .webm
- **Archives**: .zip, .tar, .gz, .rar, .7z

## Database Integration

### PostgreSQL Client Features

- **Connection Pooling**: asyncpg with 10-50 connections
- **Prepared Statements**: Cached SQL for performance
- **Transaction Support**: ACID compliance with rollback
- **Circuit Breaker**: Resilience pattern for failures
- **Health Monitoring**: Connection and query metrics
- **Pool Exhaustion Detection**: Automatic monitoring and alerting for >90% utilization

## API Endpoints

### Core Endpoints (Unified Response Format)

- `POST /stamp` - Create metadata stamp with O.N.E. v0.1 compliance
- `POST /validate` - Validate existing stamps in content
- `POST /hash` - Generate BLAKE3 hash (<2ms target)
- `GET /stamp/{file_hash}` - Retrieve stamp by hash
- `GET /health` - Service health and component status
- `GET /metrics` - Performance metrics (Prometheus format)

### Planned Endpoints (Models Ready)

- `POST /batch` - Multi-content stamping
- `POST /validate-protocol` - O.N.E. v0.1 protocol compliance
- `GET /namespace/{namespace}` - Query stamps by namespace

**Interactive API Docs:** http://localhost:8053/docs (local) or http://192.168.86.200:8053/docs (remote)
**Complete API Reference:** [docs/api/API_REFERENCE.md](./docs/api/API_REFERENCE.md)

## Testing Strategy

### Test Focus

Comprehensive testing approach for bridge/demo repository:
- **Performance Benchmarks**: Verify core performance requirements (<2ms hash generation)
- **Integration Tests**: End-to-end workflow validation
- **Load Tests**: Concurrent request handling and stability

### Performance Thresholds

```python
PERFORMANCE_THRESHOLDS = {
    'blake3_hash_generation': {
        'p99_execution_time_ms': 2.0,
        'avg_execution_time_ms': 1.0
    },
    'api_response_time': {
        'p95_response_time_ms': 10.0,
        'load_test_success_rate': 0.95
    },
    'database_operations': {
        'p95_query_time_ms': 5.0,
        'connection_pool_efficiency': 0.90
    }
}
```

## Development Environment

**Prerequisites:**

**PostgreSQL Extensions** (Required before running migrations):

This project requires PostgreSQL extensions that need superuser privileges to create:
- `uuid-ossp` - UUID generation (REQUIRED)
- `pg_stat_statements` - Query performance tracking (RECOMMENDED)

**Setup Options**:
1. **Automated Setup** (Recommended):
   ```bash
   # Set environment variables
   export POSTGRES_USER=postgres
   export POSTGRES_DB=omninode_bridge
   bash deployment/scripts/setup_postgres_extensions.sh
   ```

2. **Manual Setup** (Connect as superuser):
   ```sql
   CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
   CREATE EXTENSION IF NOT EXISTS "pg_stat_statements";
   ```

**See:** [Database Migrations](./migrations/README.md) for migration procedures and troubleshooting.

**Remote Infrastructure Configuration:**

All omninode_bridge infrastructure runs on **192.168.86.200** (remote server). Hostname resolution is already configured in /etc/hosts:

```bash
# Infrastructure running on 192.168.86.200 (remote server)
192.168.86.200 omninode-bridge-redpanda
192.168.86.200 omninode-bridge-consul
192.168.86.200 omninode-bridge-postgres
```

**Service Endpoints:**
- **Redpanda (Kafka)**: 192.168.86.200:9092
- **PostgreSQL**: 192.168.86.200:5436/omninode_bridge
- **Consul**: 192.168.86.200:28500

**Note:** This is **Kafka/Redpanda-specific** due to its two-step broker discovery protocol. Hostname resolution enables proper broker discovery.

**Quick Start:**
```bash
poetry install
docker compose -f deployment/docker-compose.yml up -d

# Setup PostgreSQL extensions (if not already done)
bash deployment/scripts/setup_postgres_extensions.sh

# Run migrations
poetry run alembic upgrade head

# Start application
poetry run uvicorn src.metadata_stamping.main:app --reload
```

**Key Dependencies:**
- Python 3.11+, FastAPI, asyncpg, blake3, pydantic v2
- Kafka clients: aiokafka (primary), confluent-kafka (fallback)

**Configuration:**
- **Remote Infrastructure**: All services on **192.168.86.200**
  - `POSTGRES_HOST=192.168.86.200` or `omninode-bridge-postgres` (via /etc/hosts)
  - `POSTGRES_PORT=5436`
  - `KAFKA_BOOTSTRAP_SERVERS=192.168.86.200:9092` or `omninode-bridge-redpanda:9092`
  - `CONSUL_HOST=192.168.86.200` or `omninode-bridge-consul`
  - `CONSUL_PORT=28500`
- Application: `SERVICE_PORT=8053`, `LOG_LEVEL=DEBUG`
- Production: Circuit breaker tuning, pool exhaustion monitoring, SSL/TLS

**Full Setup Guide:** See [docs/SETUP.md](./docs/SETUP.md)

## Deployment Prerequisites

**‚ö†Ô∏è CRITICAL: Database migrations must be applied before starting services**

### Pre-Deployment Checklist

Before deploying to any environment (development, staging, or production), complete these steps:

1. **PostgreSQL Extensions** - Create required extensions (requires superuser privileges):
   ```bash
   # Automated setup (recommended)
   bash deployment/scripts/setup_postgres_extensions.sh

   # OR manual setup
   psql -h <host> -U postgres -d omninode_bridge << 'EOF'
   CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
   CREATE EXTENSION IF NOT EXISTS "pg_stat_statements";
   EOF
   ```

2. **Database Migrations** - Apply all schema migrations:
   ```bash
   # Apply all migrations in order
   for migration in migrations/00*.sql migrations/01*.sql; do
       if [[ ! $migration =~ rollback ]]; then
           echo "Applying: $migration"
           psql -h <host> -U postgres -d omninode_bridge -f "$migration"
       fi
   done
   ```

3. **Verify Critical Tables** - Ensure all tables exist:
   ```bash
   # Check for node_registrations table (Migration 005 - CRITICAL)
   psql -h <host> -U postgres -d omninode_bridge -c "\d node_registrations"

   # Verify all tables
   psql -h <host> -U postgres -d omninode_bridge -c "\dt"
   ```

4. **Environment Variables** - Configure required settings:
   - `POSTGRES_HOST`, `POSTGRES_PORT`, `POSTGRES_DATABASE`
   - `POSTGRES_USER`, `POSTGRES_PASSWORD` (use secrets manager for production)
   - `KAFKA_BOOTSTRAP_SERVERS`
   - `CONSUL_HOST`, `CONSUL_PORT`
   - `LOG_LEVEL` (DEBUG/INFO/WARNING/ERROR)

5. **Production-Specific** (if deploying to production):
   - Create database backup before migrations
   - Test migrations on staging environment first
   - Review [Pre-Deployment Checklist](./docs/deployment/PRE_DEPLOYMENT_CHECKLIST.md)
   - Configure SSL/TLS certificates
   - Set up monitoring and alerting

**Documentation:**
- **[Database Migrations](./migrations/README.md)** - Migration procedures and troubleshooting
- **[Pre-Deployment Checklist](./docs/deployment/PRE_DEPLOYMENT_CHECKLIST.md)** - Comprehensive deployment readiness verification
- **[Secure Deployment Guide](./docs/deployment/SECURE_DEPLOYMENT_GUIDE.md)** - Production security best practices

**Common Issues:**
- **Missing node_registrations table**: Migration 005 not applied ‚Üí Run migration manually
- **Extension errors**: Extensions not created ‚Üí Run setup_postgres_extensions.sh
- **Permission denied**: Database user lacks CREATE privileges ‚Üí Grant proper permissions

## Success Criteria

### Functionality
- All API endpoints operational with omnibase_core compliance
- BLAKE3 hash generation with <2ms performance target
- Database operations optimized with connection pooling
- Multi-modal file type detection and processing

### Performance
- Hash generation: 99th percentile < 2ms, average < 1ms
- API response: 95th percentile < 10ms under normal load
- Load testing: 95%+ success rate with 1000+ concurrent requests
- Memory usage: < 512MB under normal operational load

### Quality
- Testing: Comprehensive unit, integration, and performance tests with focus on critical paths
- Code quality: Clean architecture with type safety and documentation
- Monitoring: Prometheus metrics and structured logging
- Security: Input validation, SQL injection protection, SSL/TLS support

## üöÄ Bridge Nodes Implementation (ONEX v2.0)

**Status**: ‚úÖ MVP Complete (October 2025)
**Type**: Production-Grade MVP Foundation

This repository provides **ONEX v2.0 compliant bridge nodes** as part of the omninode ecosystem MVP. These are production-quality implementations that will be extracted into dedicated repositories as the system matures.

### üìã What This Repository Contains

**Bridge Nodes** (MVP Implementation):
- **NodeBridgeOrchestrator** - Workflow coordination and service routing
- **NodeBridgeReducer** - Streaming aggregation and state management
- **NodeBridgeRegistry** - Service discovery and node registration
- Event infrastructure (13 Kafka topics, OnexEnvelopeV1 format)
- Database persistence layer (PostgreSQL with 5 migrations)
- Comprehensive testing (501 tests, 92.8% passing)

**Repository Evolution Plan:**
- **Current**: Unified MVP repository for rapid development
- **Future**: Split into specialized repos (omninode-events, omninode-bridge-nodes, omninode-persistence, etc.)
- **Timeline**: Post-MVP completion, as functionality stabilizes

### Architecture Overview

```
MetadataStampingService API
         ‚Üì (stamp requests)
NodeBridgeOrchestrator
    - Workflow coordination
    - Service routing (MetadataStamping, OnexTree)
    - FSM state management (pending ‚Üí processing ‚Üí completed/failed)
    - Event publishing to Kafka
         ‚Üì (stamped content + metadata)
NodeBridgeReducer
    - Streaming aggregation (>1000 items/sec)
    - Namespace-based grouping
    - FSM state tracking
    - PostgreSQL persistence
         ‚Üì
PostgreSQL Bridge State Store
```

### Implementation Status

**‚úÖ Completed Components:**
1. **NodeBridgeOrchestrator** - Full workflow coordination with multi-step execution
2. **NodeBridgeReducer** - Async streaming aggregation architecture
3. **Data Models** - All Pydantic v2 compliant with FSM state enum
4. **Kafka Event Publishing** - Full integration with aiokafka/confluent-kafka for event streaming
5. **OnexTree Intelligence Client** - HTTP client with circuit breaker and resilience patterns
6. **LlamaIndex Workflows** - Event-driven orchestration framework integration

‚è≥ **Pending Components:**
- Contract YAML files (currently placeholders)
- Comprehensive unit and integration test coverage
- PostgreSQL persistence layer (connection manager implemented, full CRUD pending)

### Key Features

**NodeBridgeOrchestrator:**
- **Performance**: <50ms for standard workflows, <150ms with OnexTree intelligence
- **Throughput**: 100+ concurrent workflows per second
- **FSM States**: PENDING, PROCESSING, COMPLETED, FAILED
- **Event Types**: 9 Kafka event types for workflow tracking

**NodeBridgeReducer:**
- **Performance**: >1000 items/second aggregation throughput
- **Latency**: <100ms for 1000 items
- **Aggregation Types**: NAMESPACE_GROUPING (primary), TIME_WINDOW, FILE_TYPE_GROUPING, SIZE_BUCKETS, WORKFLOW_GROUPING, CUSTOM
- **Multi-Tenant**: Namespace-based isolation and grouping

### üõ†Ô∏è Development Workflow (Bridge Implementation)

```bash
# Run bridge nodes for development/testing
python -m omninode_bridge.nodes.orchestrator.v1_0_0.node
python -m omninode_bridge.nodes.reducer.v1_0_0.node
python -m omninode_bridge.nodes.registry.v1_0_0.node

# Start development environment
docker compose -f deployment/docker-compose.bridge.yml up -d

# Run tests and validation
pytest tests/
pytest tests/integration/ -v
pytest tests/performance/ -m performance
```

### ‚ö†Ô∏è Important Usage Notes

- **MVP Status**: These are production-quality implementations for MVP validation
- **Repository Split**: Functionality will be extracted to dedicated repos post-MVP
- **Integration Ready**: Full omnibase_core integration with event infrastructure
- **Performance Validated**: Exceeds targets by 30-424x in key areas
- **Test Coverage**: 92.8% overall, 100% for critical paths (event schemas, entity models)

**Production Readiness:**
The MVP is production-quality but housed in a monorepo. Before production deployment, functionality will be split into dedicated repositories with proper CI/CD, deployment configurations, and operations setup.

### Documentation

Comprehensive documentation available:
- **[Bridge Nodes Guide](./docs/guides/BRIDGE_NODES_GUIDE.md)** - Implementation guide, FSM patterns, integration
- **[API Reference](./docs/api/API_REFERENCE.md)** - Complete API documentation with examples
- **[Implementation Plan](./docs/planning/BRIDGE_NODE_IMPLEMENTATION_PLAN.md)** - Original implementation plan (now mostly complete)

### Next Steps for Bridge Nodes

1. **Complete Contract YAMLs** - Define subcontract references and configurations
2. **Add Tests** - Unit tests for both nodes, integration tests for workflows
3. **Implement PostgreSQL Integration** - Replace persistence hooks with actual DB writes
4. **Implement Kafka Integration** - Add event producer for real Kafka publishing
5. **Implement OnexTree Client** - HTTP client for intelligence service
6. **Performance Testing** - Load tests for orchestration and aggregation
7. **Horizontal Scaling** - Multi-instance deployment with shared state

## üîÑ LlamaIndex Workflows Integration

**Status**: ‚úÖ Integrated (October 2025)
**Purpose**: Event-driven orchestration framework for complex AI agent workflows

**Key Features:**
- Event-driven workflow architecture with state management
- Parallel step execution and intelligent routing
- Integration with Bridge Orchestrator for workflow coordination
- Performance: 1000+ events/second, <100ms latency for simple workflows

**Core Components:**
1. **Workflow Class** - Main orchestration container
2. **Events** - Typed data carriers between steps
3. **Steps** - Decorated async functions that process events
4. **Context** - Shared state across workflow execution
5. **State Management** - Persistent state tracking

**Documentation:**
- **[LlamaIndex Workflows Guide](./docs/LLAMAINDEX_WORKFLOWS_GUIDE.md)** - Complete integration guide with patterns and examples
- **[Official Docs](https://docs.llamaindex.ai/en/stable/understanding/workflows/)** - LlamaIndex official documentation
- **Note**: Integration with Bridge Orchestrator for workflow coordination

**Quick Example:**
```python
from llama_index.core.workflow import Workflow, step, StartEvent, StopEvent

class IntelligenceWorkflow(Workflow):
    @step
    async def entry_point(self, ctx: Context, ev: StartEvent) -> CustomEvent:
        ctx.data["session_id"] = str(uuid4())
        return CustomEvent(data=ev.input_data)

    @step
    async def process(self, ctx: Context, ev: CustomEvent) -> StopEvent:
        result = await self._process_intelligence(ev.data)
        return StopEvent(result=result)

# Usage
workflow = IntelligenceWorkflow(timeout=60.0)
result = await workflow.run(input_data={"query": "Find optimization patterns"})
```

## Project Status

**Current Phase:** MVP Foundation Complete ‚úÖ (Phase 1 & 2)
**Next Phase:** MVP Validation & Repository Split Planning

**Recent Cleanup:** Closed 6 stale PRs (#6-9, #16-17) containing speculative features.

**Strategic Focus:** Complete functional MVP in unified repository, then split into specialized repos as functionality matures.

**Repository Evolution:**
- **Now**: Unified MVP repository (omninode_bridge)
- **Future**: Split repos (omninode-events, omninode-bridge-nodes, omninode-persistence, etc.)
- **Timeline**: Post-MVP validation

**Roadmap:** See [docs/ROADMAP.md](./docs/ROADMAP.md)

## Comprehensive Documentation

### Quick Navigation

**New to OmniNode Bridge?** Start here:
- üöÄ **[Getting Started](./docs/GETTING_STARTED.md)** - 5-minute quick start guide
- üìö **[Documentation Index](./docs/INDEX.md)** - Complete documentation hub with all guides

**Core Documentation**:
- **[Architecture Guide](./docs/architecture/ARCHITECTURE.md)** - System architecture, ONEX v2.0 compliance, design patterns
- **[Database Guide](./docs/database/DATABASE_GUIDE.md)** - Schema, migrations, performance, operations
- **[Database Migrations](./migrations/README.md)** - PostgreSQL extension requirements, migration procedures, troubleshooting
- **[API Reference](./docs/api/API_REFERENCE.md)** - Complete API documentation with examples
- **[Bridge Nodes Guide](./docs/guides/BRIDGE_NODES_GUIDE.md)** - Bridge node implementation guide
- **Event System Guide** ‚úÖ *(Complete)* - Kafka infrastructure with 13 topics, OnexEnvelopeV1 format, and event schemas
- **[Setup Guide](./docs/SETUP.md)** - Complete development environment setup
- **[Contributing Guide](./docs/CONTRIBUTING.md)** - Contribution guidelines and best practices

**Migration Guides**:
- **[Phase 3 to Phase 4 Migration](./docs/guides/PHASE_3_TO_PHASE_4_MIGRATION.md)** - Complete migration guide from Intelligent Code Generation (Phase 3) to Agent Coordination & Workflows (Phase 4)

**Deployment Documentation**:
- **[Deployment System Migration](./docs/deployment/DEPLOYMENT_SYSTEM_MIGRATION.md)** - Migration strategy from manual scripts to automated ONEX workflows
- **[Pre-Deployment Checklist](./docs/deployment/PRE_DEPLOYMENT_CHECKLIST.md)** - Production deployment readiness checklist
- **[Secure Deployment Guide](./docs/deployment/SECURE_DEPLOYMENT_GUIDE.md)** - Security best practices for production
- **[Remote Migration Guide](./docs/deployment/REMOTE_MIGRATION_GUIDE.md)** - Complete guide for migrating containers to remote systems

**Additional Resources**:
- **[Database Schema](./migrations/schema.sql)** - PostgreSQL schema with O.N.E. v0.1 compliance
- **[Extension Setup Script](./deployment/scripts/setup_postgres_extensions.sh)** - Automated PostgreSQL extension setup
- **[Roadmap](./docs/ROADMAP.md)** - Implementation timeline and future plans
- **[LlamaIndex Workflows](./docs/LLAMAINDEX_WORKFLOWS_GUIDE.md)** - Event-driven workflow integration

## üîÑ Deployment System Architecture

**Status**: ‚è≥ Transition in Progress (Manual Scripts ‚Üí Automated Workflow)
**Strategy**: Phased validation with parallel operation

### Current Deployment Approach

OmniNode Bridge uses a **dual deployment system** during the transition to automated ONEX v2.0 workflows:

**1. Manual Shell Scripts (Production-Ready)**
- ‚úÖ **Status**: Battle-tested and reliable
- ‚úÖ **Use When**: Production deployments, emergency rollback
- ‚úÖ **Location**: `scripts/` directory (`migrate-to-remote.sh`, `rebuild-service.sh`)

**2. Automated ONEX Workflow (Validation Phase)**
- üöß **Status**: Implementation complete, validation in progress
- üöß **Use When**: Testing, validation, non-critical deployments
- üöß **Location**: `nodes/deployment_sender_effect`, `nodes/deployment_receiver_effect`

### When to Use Each System

**Use Manual Scripts** (`scripts/rebuild-service.sh`) when:
- Deploying to production (192.168.86.200)
- Emergency rollback required
- Quick service rebuild after code changes
- Validating automated system itself

**Use Automated Workflow** (`deployment_workflow.yaml`) when:
- Testing deployment automation
- Validating ONEX v2.0 compliance
- Gathering deployment metrics
- Building observability via Kafka events

### Migration Timeline

```
Phase 1 (Weeks 1-4): Validation
‚îú‚îÄ Deploy receiver node using scripts
‚îú‚îÄ Test sender node locally
‚îú‚îÄ Validate end-to-end workflow
‚îî‚îÄ Measure performance metrics

Phase 2 (Weeks 5-6): Parallel Operation
‚îú‚îÄ Use both scripts AND nodes
‚îú‚îÄ Compare reliability and performance
‚îî‚îÄ Build team confidence

Phase 3 (Weeks 7-10): Deprecation
‚îú‚îÄ Rename scripts to .deprecated
‚îú‚îÄ Update all documentation
‚îî‚îÄ Archive scripts after 30+ successful node-based deployments
```

### Key Differences

| Aspect | Manual Scripts | Automated Workflow |
|--------|----------------|-------------------|
| **Invocation** | Manual execution | Orchestrated via contract |
| **Observability** | Logs only | Kafka events + metrics |
| **Quality Gates** | Manual validation | Automated checkpoints |
| **Rollback** | Manual restore | Automated rollback |
| **Multi-Service** | Sequential scripts | Coordinated workflow |
| **Performance** | ~50s per service | Target: <30s with validation |

### Bootstrap Deployment Pattern

**Critical**: Use manual scripts to deploy the automated deployment system itself:

```bash
# Step 1: Deploy receiver node using rebuild-service.sh
./scripts/rebuild-service.sh deployment-receiver 192.168.86.200

# Step 2: Verify receiver is healthy
curl http://192.168.86.200:8001/health

# Step 3: Now use automated workflow for subsequent deployments
# (Receiver is available to handle node-based deployments)
```

**Documentation**:
- **[Deployment System Migration Guide](./docs/deployment/DEPLOYMENT_SYSTEM_MIGRATION.md)** - Complete migration strategy, validation criteria, and transition checklist
- **[Remote Migration Guide](./docs/deployment/REMOTE_MIGRATION_GUIDE.md)** - Manual script usage and procedures

## üöÄ Remote Migration & Deployment

**Status**: ‚úÖ Complete (October 2025)
**Purpose**: Simplified container migration to remote systems with automated deployment

### Migration Scripts

**Three-Script Solution** for complete remote deployment:

1. **`scripts/migrate-to-remote.sh`** - Complete migration from local to remote system
2. **`scripts/setup-remote.sh`** - Remote system configuration and deployment
3. **`scripts/rebuild-service.sh`** - Rebuild and redeploy specific services

### Quick Migration

```bash
# 1. Update username in migrate-to-remote.sh
REMOTE_USER="your_username"

# 2. Run migration (handles everything automatically)
./scripts/migrate-to-remote.sh
```

### Service Rebuild

```bash
# Rebuild specific services after code changes
./scripts/rebuild-service.sh orchestrator
./scripts/rebuild-service.sh reducer
./scripts/rebuild-service.sh hook-receiver
```

### Remote Management

```bash
# SSH to remote system
ssh your_username@192.168.86.200

# Use management script
cd ~/omninode_bridge
./manage-bridge.sh status    # Show container status
./manage-bridge.sh logs      # Show logs
./manage-bridge.sh restart   # Restart services
```

### Service URLs (Post-Migration)

- **Hook Receiver**: http://192.168.86.200:8001
- **Orchestrator**: http://192.168.86.200:8060
- **Reducer**: http://192.168.86.200:8061
- **Metadata Stamping**: http://192.168.86.200:8057
- **OnexTree**: http://192.168.86.200:8058
- **Consul UI**: http://192.168.86.200:28500
- **Vault UI**: http://192.168.86.200:8200

**Documentation**: **[Remote Migration Guide](./docs/deployment/REMOTE_MIGRATION_GUIDE.md)** - Complete migration procedures, troubleshooting, and management

## Scripts Reference

All utility scripts are organized in the `scripts/` directory. Key scripts include:

### Deployment & Migration
- **`scripts/migrate-to-remote.sh`** - Complete migration from local to remote system
- **`scripts/setup-remote.sh`** - Remote system setup and configuration
- **`scripts/rebuild-service.sh`** - Rebuild and redeploy specific services
- **`scripts/run-integration-tests-remote.sh`** - Run integration tests against remote infrastructure

### Testing & Validation
- **`scripts/test-local.sh`** - Run tests against local infrastructure
- **`scripts/test-remote.sh`** - Run tests against remote infrastructure
- **`scripts/test_execution_strategy.py`** - Intelligent test execution strategy
- **`scripts/comprehensive_test_execution.py`** - Comprehensive test runner with retry logic
- **`scripts/selective_test_runner.py`** - Run tests selectively based on changes

### Database & Setup
- **`deployment/scripts/setup_postgres_extensions.sh`** - Setup required PostgreSQL extensions
- **`deployment/scripts/manage_metric_partitions.sh`** - Manage metric table partitions (create, drop, verify)
- **`scripts/db_migrate.py`** - Database migration helper

### Code Quality & Validation
- **`scripts/validate_one_compliance.py`** - Validate O.N.E. v0.1 compliance
- **`scripts/validate_onex_canonical.py`** - Validate ONEX canonical patterns
- **`scripts/validate_onex_patterns.py`** - Validate ONEX design patterns
- **`scripts/validate-formatting-consistency.sh`** - Check code formatting consistency
- **`scripts/security-config.sh`** - Security configuration validation
- **`scripts/security_scan.sh`** - Run security scans

### Kafka & Event Infrastructure
- **`scripts/create_mvp_kafka_topics.py`** - Create MVP Kafka topics
- **`scripts/create_codegen_kafka_topics.py`** - Create code generation Kafka topics
- **`scripts/setup-kafka-hostname.sh`** - Setup Kafka hostname resolution

### Git & CI/CD
- **`scripts/install_git_hooks.sh`** - Install git pre-commit hooks
- **`scripts/pre-commit-workflow-validation.py`** - Validate workflows in pre-commit
- **`scripts/test_git_hook.sh`** - Test git hooks

### Performance & Benchmarking
- **`scripts/benchmark_codegen.py`** - Benchmark code generation performance
- **`scripts/simple_one_test_runner.py`** - Simple O.N.E. test runner with metrics

**Note**: Most scripts include `--help` flag for usage information.

This Phase 1 & 2 implementation establishes a solid foundation for both the MetadataStampingService and the Bridge Nodes with focus on performance, reliability, and omninode ecosystem compliance.
